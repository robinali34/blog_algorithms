<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://robinali34.github.io/blog_algorithms//blog_algorithms/feed.xml" rel="self" type="application/atom+xml" /><link href="https://robinali34.github.io/blog_algorithms//blog_algorithms/" rel="alternate" type="text/html" /><updated>2025-11-22T07:09:53+00:00</updated><id>https://robinali34.github.io/blog_algorithms//blog_algorithms/feed.xml</id><title type="html">Robina Li</title><subtitle>Algorithms Blog - Graduate Algorithms course notes and resources</subtitle><entry><title type="html">Linear Programming Fundamentals: Theory, Algorithms, and Applications</title><link href="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/linear-programming-fundamentals/" rel="alternate" type="text/html" title="Linear Programming Fundamentals: Theory, Algorithms, and Applications" /><published>2025-11-21T00:00:00+00:00</published><updated>2025-11-21T00:00:00+00:00</updated><id>https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/linear-programming-fundamentals</id><content type="html" xml:base="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/linear-programming-fundamentals/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>Linear Programming (LP) is one of the most important and widely used optimization techniques in computer science, operations research, and applied mathematics. Unlike many optimization problems that are NP-complete, Linear Programming can be solved efficiently in polynomial time, making it a powerful tool for solving real-world optimization problems. This post provides a comprehensive introduction to Linear Programming, covering its theory, algorithms, and applications.</p>

<h2 id="what-is-linear-programming">What is Linear Programming?</h2>

<p>Linear Programming is a mathematical optimization technique for finding the best outcome (maximum or minimum) of a linear objective function subject to linear equality and inequality constraints.</p>

<h3 id="problem-definition">Problem Definition</h3>

<p><strong>Linear Programming Problem:</strong></p>

<p><strong>Input:</strong></p>
<ul>
  <li>Variables: x₁, x₂, …, x_n (real numbers)</li>
  <li>Objective function: c₁x₁ + c₂x₂ + … + c_nx_n (linear)</li>
  <li>Constraints: Linear inequalities or equations</li>
  <li>Domain: Variables may be restricted (e.g., xᵢ ≥ 0)</li>
</ul>

<p><strong>Output:</strong></p>
<ul>
  <li>Values for variables that satisfy all constraints</li>
  <li>Optimize (maximize or minimize) the objective function</li>
</ul>

<h3 id="key-characteristics">Key Characteristics</h3>

<ol>
  <li><strong>Linearity:</strong> All functions (objective and constraints) are linear</li>
  <li><strong>Continuous Variables:</strong> Variables can take any real values (unlike integer programming)</li>
  <li><strong>Convexity:</strong> Feasible region is a convex polyhedron</li>
  <li><strong>Polynomial-Time Solvable:</strong> Can be solved efficiently</li>
</ol>

<h2 id="standard-forms">Standard Forms</h2>

<p>Linear Programming problems can be written in different standard forms. Understanding these forms is crucial for applying algorithms.</p>

<h3 id="standard-form-inequality-form">Standard Form (Inequality Form)</h3>

<p><strong>Maximize:</strong> c^T x</p>

<p><strong>Subject to:</strong></p>
<ul>
  <li>Ax ≤ b</li>
  <li>x ≥ 0</li>
</ul>

<p>Where:</p>
<ul>
  <li>A is an m × n matrix (constraint coefficients)</li>
  <li>b is an m-dimensional vector (right-hand side)</li>
  <li>c is an n-dimensional vector (objective coefficients)</li>
  <li>x is an n-dimensional vector (decision variables)</li>
</ul>

<h3 id="canonical-form-equality-form">Canonical Form (Equality Form)</h3>

<p><strong>Maximize:</strong> c^T x</p>

<p><strong>Subject to:</strong></p>
<ul>
  <li>Ax = b</li>
  <li>x ≥ 0</li>
</ul>

<p><strong>Conversion:</strong> Add slack variables to convert inequalities to equalities:</p>
<ul>
  <li>Constraint: a₁x₁ + a₂x₂ ≤ b becomes a₁x₁ + a₂x₂ + s = b, s ≥ 0</li>
  <li>Slack variable s represents the “slack” or unused capacity</li>
</ul>

<h3 id="general-form-conversions">General Form Conversions</h3>

<p><strong>Minimization → Maximization:</strong></p>
<ul>
  <li>Minimize c^T x ↔ Maximize -c^T x</li>
</ul>

<p><strong>Unrestricted Variables:</strong></p>
<ul>
  <li>Variable x unrestricted ↔ Replace with x = x⁺ - x⁻ where x⁺, x⁻ ≥ 0</li>
</ul>

<p><strong>≥ Constraints:</strong></p>
<ul>
  <li>a^T x ≥ b ↔ -a^T x ≤ -b</li>
</ul>

<p><strong>Equality Constraints:</strong></p>
<ul>
  <li>a^T x = b ↔ a^T x ≤ b and a^T x ≥ b</li>
</ul>

<h2 id="geometric-interpretation">Geometric Interpretation</h2>

<p>Understanding the geometry of Linear Programming provides crucial intuition.</p>

<h3 id="feasible-region">Feasible Region</h3>

<p><strong>Definition:</strong> The set of all points x that satisfy all constraints.</p>

<p><strong>Properties:</strong></p>
<ul>
  <li><strong>Convex Polyhedron:</strong> Intersection of half-spaces (from inequalities)</li>
  <li><strong>Vertices:</strong> Corner points of the polyhedron</li>
  <li><strong>Edges:</strong> Lines connecting vertices</li>
  <li><strong>Faces:</strong> Flat surfaces bounding the polyhedron</li>
</ul>

<h3 id="fundamental-theorem-of-linear-programming">Fundamental Theorem of Linear Programming</h3>

<p><strong>Theorem:</strong> If an LP has an optimal solution, then there exists an optimal solution at a vertex (extreme point) of the feasible region.</p>

<p><strong>Implications:</strong></p>
<ul>
  <li>We only need to check vertices, not all points</li>
  <li>This is why algorithms like Simplex work (they move between vertices)</li>
  <li>Number of vertices can be exponential, but algorithms are still efficient</li>
</ul>

<h3 id="example-2d-visualization">Example: 2D Visualization</h3>

<p>Consider the LP:</p>

<p><strong>Maximize:</strong> 3x₁ + 2x₂</p>

<p><strong>Subject to:</strong></p>
<ul>
  <li>2x₁ + x₂ ≤ 6</li>
  <li>x₁ + 2x₂ ≤ 8</li>
  <li>x₁, x₂ ≥ 0</li>
</ul>

<p><strong>Feasible Region:</strong></p>
<ul>
  <li>Bounded polygon (quadrilateral)</li>
  <li>Vertices: (0,0), (0,4), (4/3, 10/3), (3,0)</li>
  <li>Optimal solution: (4/3, 10/3) with value 32/3 ≈ 10.67</li>
</ul>

<p><strong>Graphical Method:</strong></p>
<ol>
  <li>Plot constraints as lines</li>
  <li>Identify feasible region (intersection of half-spaces)</li>
  <li>Plot objective function as a line</li>
  <li>Move objective line parallel to itself to find optimal vertex</li>
</ol>

<h2 id="algorithms-for-linear-programming">Algorithms for Linear Programming</h2>

<h3 id="1-simplex-method">1. Simplex Method</h3>

<p><strong>Inventor:</strong> George Dantzig (1947)</p>

<p><strong>Basic Idea:</strong> Move from vertex to vertex along edges, improving objective at each step.</p>

<p><strong>Algorithm Outline:</strong></p>
<ol>
  <li>Start at a feasible vertex (basic feasible solution)</li>
  <li>While not optimal:
    <ul>
      <li>Choose a non-basic variable to enter basis (improves objective)</li>
      <li>Choose a basic variable to leave basis (maintains feasibility)</li>
      <li>Pivot: update tableau</li>
    </ul>
  </li>
  <li>Return optimal solution</li>
</ol>

<p><strong>Key Concepts:</strong></p>
<ul>
  <li><strong>Basic Variables:</strong> Variables set to their bounds (usually 0)</li>
  <li><strong>Non-Basic Variables:</strong> Variables that can change</li>
  <li><strong>Basis:</strong> Set of basic variables</li>
  <li><strong>Tableau:</strong> Matrix representation of the LP</li>
  <li><strong>Pivoting:</strong> Moving from one basis to another</li>
</ul>

<p><strong>Advantages:</strong></p>
<ul>
  <li>Very efficient in practice</li>
  <li>Often requires O(m) to O(m+n) iterations</li>
  <li>Can handle degeneracy</li>
</ul>

<p><strong>Disadvantages:</strong></p>
<ul>
  <li>Exponential worst-case time (Klee-Minty examples)</li>
  <li>Can cycle if not careful (Bland’s rule prevents this)</li>
</ul>

<p><strong>Time Complexity:</strong></p>
<ul>
  <li><strong>Worst-case:</strong> Exponential (2^n iterations possible)</li>
  <li><strong>Average-case:</strong> Polynomial (O(m+n) iterations typical)</li>
  <li><strong>Practical:</strong> Very fast, often faster than polynomial methods</li>
</ul>

<h3 id="2-ellipsoid-method">2. Ellipsoid Method</h3>

<p><strong>Inventor:</strong> Leonid Khachiyan (1979)</p>

<p><strong>Basic Idea:</strong> Shrink an ellipsoid containing the feasible region until finding a solution.</p>

<p><strong>Algorithm Outline:</strong></p>
<ol>
  <li>Start with large ellipsoid containing feasible region</li>
  <li>While ellipsoid is large:
    <ul>
      <li>Check if center is feasible</li>
      <li>If not, use violated constraint to shrink ellipsoid</li>
      <li>Update ellipsoid</li>
    </ul>
  </li>
  <li>Return solution</li>
</ol>

<p><strong>Significance:</strong></p>
<ul>
  <li><strong>First polynomial-time algorithm</strong> for LP</li>
  <li>Proved LP ∈ P theoretically</li>
</ul>

<p><strong>Time Complexity:</strong></p>
<ul>
  <li>O(n^4 L) where L is input size (bit complexity)</li>
</ul>

<p><strong>Disadvantages:</strong></p>
<ul>
  <li>Large constants make it impractical</li>
  <li>Not used in practice</li>
</ul>

<h3 id="3-interior-point-methods">3. Interior-Point Methods</h3>

<p><strong>Inventor:</strong> Narendra Karmarkar (1984)</p>

<p><strong>Basic Idea:</strong> Move through the interior of the feasible region toward the optimal solution.</p>

<p><strong>Algorithm Outline:</strong></p>
<ol>
  <li>Start at interior point</li>
  <li>While not optimal:
    <ul>
      <li>Compute search direction (toward optimal)</li>
      <li>Choose step size (stay in interior)</li>
      <li>Update solution</li>
    </ul>
  </li>
  <li>Return optimal solution</li>
</ol>

<p><strong>Key Concepts:</strong></p>
<ul>
  <li><strong>Barrier Function:</strong> Keeps solution away from boundaries</li>
  <li><strong>Newton’s Method:</strong> Used to compute search direction</li>
  <li><strong>Path-Following:</strong> Follow central path to optimal solution</li>
</ul>

<p><strong>Advantages:</strong></p>
<ul>
  <li>Polynomial-time: O(n^{3.5} L)</li>
  <li>Practical and efficient</li>
  <li>Widely used in modern solvers</li>
</ul>

<p><strong>Time Complexity:</strong></p>
<ul>
  <li>O(n^{3.5} L) using path-following methods</li>
  <li>Typically O(√n log(1/ε)) iterations for ε-accuracy</li>
</ul>

<p><strong>Modern Variants:</strong></p>
<ul>
  <li>Primal-dual interior-point methods</li>
  <li>Predictor-corrector methods</li>
  <li>Self-dual embedding</li>
</ul>

<h3 id="4-comparison-of-methods">4. Comparison of Methods</h3>

<table>
  <thead>
    <tr>
      <th>Method</th>
      <th>Worst-Case</th>
      <th>Average-Case</th>
      <th>Practical Use</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Simplex</td>
      <td>Exponential</td>
      <td>Polynomial</td>
      <td>Very common</td>
    </tr>
    <tr>
      <td>Ellipsoid</td>
      <td>Polynomial</td>
      <td>Polynomial</td>
      <td>Rarely used</td>
    </tr>
    <tr>
      <td>Interior-Point</td>
      <td>Polynomial</td>
      <td>Polynomial</td>
      <td>Very common</td>
    </tr>
  </tbody>
</table>

<p><strong>Modern Solvers:</strong> Use combination of methods:</p>
<ul>
  <li>Simplex for warm starts</li>
  <li>Interior-point for initial solution</li>
  <li>Hybrid approaches</li>
</ul>

<h2 id="duality-theory">Duality Theory</h2>

<p>Duality is one of the most beautiful and powerful concepts in Linear Programming.</p>

<h3 id="primal-and-dual-problems">Primal and Dual Problems</h3>

<p><strong>Primal LP:</strong></p>
<ul>
  <li>Maximize c^T x</li>
  <li>Subject to Ax ≤ b, x ≥ 0</li>
</ul>

<p><strong>Dual LP:</strong></p>
<ul>
  <li>Minimize b^T y</li>
  <li>Subject to A^T y ≥ c, y ≥ 0</li>
</ul>

<p><strong>Key Relationship:</strong> Every LP has a corresponding dual LP.</p>

<h3 id="duality-theorems">Duality Theorems</h3>

<p><strong>Weak Duality Theorem:</strong></p>
<ul>
  <li>For any feasible x (primal) and y (dual): c^T x ≤ b^T y</li>
  <li>Dual provides upper bound for primal (maximization)</li>
  <li>Primal provides lower bound for dual (minimization)</li>
</ul>

<p><strong>Strong Duality Theorem:</strong></p>
<ul>
  <li>If both primal and dual have feasible solutions, then:
    <ul>
      <li>Primal optimal = Dual optimal</li>
    </ul>
  </li>
  <li>If one is unbounded, the other is infeasible</li>
  <li>If one is infeasible, the other is either infeasible or unbounded</li>
</ul>

<p><strong>Complementary Slackness:</strong></p>
<ul>
  <li>At optimality:
    <ul>
      <li>If constraint is not tight, corresponding dual variable = 0</li>
      <li>If dual constraint is not tight, corresponding primal variable = 0</li>
    </ul>
  </li>
</ul>

<h3 id="economic-interpretation">Economic Interpretation</h3>

<p><strong>Primal:</strong> Resource allocation problem</p>
<ul>
  <li>Variables: Amount of each activity</li>
  <li>Objective: Maximize profit</li>
  <li>Constraints: Resource limitations</li>
</ul>

<p><strong>Dual:</strong> Pricing problem</p>
<ul>
  <li>Variables: Prices (shadow prices) of resources</li>
  <li>Objective: Minimize total cost</li>
  <li>Constraints: Activities must be profitable</li>
</ul>

<p><strong>Shadow Prices:</strong> Dual variables represent the value of an additional unit of each resource.</p>

<h3 id="example-duality">Example: Duality</h3>

<p><strong>Primal:</strong></p>
<ul>
  <li>Maximize: 3x₁ + 2x₂</li>
  <li>Subject to: 2x₁ + x₂ ≤ 6, x₁ + 2x₂ ≤ 8, x₁, x₂ ≥ 0</li>
</ul>

<p><strong>Dual:</strong></p>
<ul>
  <li>Minimize: 6y₁ + 8y₂</li>
  <li>Subject to: 2y₁ + y₂ ≥ 3, y₁ + 2y₂ ≥ 2, y₁, y₂ ≥ 0</li>
</ul>

<p><strong>Optimal Solutions:</strong></p>
<ul>
  <li>Primal: (4/3, 10/3) with value 32/3</li>
  <li>Dual: (4/3, 1/3) with value 32/3</li>
  <li>Both have same optimal value (Strong Duality)</li>
</ul>

<h2 id="special-cases-and-degeneracy">Special Cases and Degeneracy</h2>

<h3 id="unbounded-problems">Unbounded Problems</h3>

<p><strong>Definition:</strong> Objective can be made arbitrarily large (maximization) or small (minimization).</p>

<p><strong>Causes:</strong></p>
<ul>
  <li>Feasible region is unbounded</li>
  <li>Objective direction points toward unbounded direction</li>
</ul>

<p><strong>Detection:</strong> Simplex method identifies unboundedness when no variable can leave basis.</p>

<h3 id="infeasible-problems">Infeasible Problems</h3>

<p><strong>Definition:</strong> No solution satisfies all constraints.</p>

<p><strong>Causes:</strong></p>
<ul>
  <li>Conflicting constraints</li>
  <li>Over-constrained problem</li>
</ul>

<p><strong>Detection:</strong> Phase I of Simplex method detects infeasibility.</p>

<h3 id="degeneracy">Degeneracy</h3>

<p><strong>Definition:</strong> More than m constraints are tight at a vertex (where m is number of constraints).</p>

<p><strong>Causes:</strong></p>
<ul>
  <li>Redundant constraints</li>
  <li>Special problem structure</li>
</ul>

<p><strong>Issues:</strong></p>
<ul>
  <li>Simplex may cycle (use Bland’s rule to prevent)</li>
  <li>May require extra iterations</li>
</ul>

<h3 id="multiple-optimal-solutions">Multiple Optimal Solutions</h3>

<p><strong>Definition:</strong> More than one optimal solution exists.</p>

<p><strong>Causes:</strong></p>
<ul>
  <li>Objective function parallel to a face of feasible region</li>
  <li>Entire face is optimal</li>
</ul>

<p><strong>Characterization:</strong> If x* and x** are both optimal, then any convex combination is also optimal.</p>

<h2 id="applications-of-linear-programming">Applications of Linear Programming</h2>

<h3 id="1-resource-allocation">1. Resource Allocation</h3>

<p><strong>Problem:</strong> Allocate limited resources to maximize profit or minimize cost.</p>

<p><strong>Example:</strong> Production planning</p>
<ul>
  <li>Resources: Labor, materials, machine time</li>
  <li>Products: Different products with different resource requirements</li>
  <li>Objective: Maximize profit</li>
</ul>

<p><strong>Formulation:</strong></p>
<ul>
  <li>Variables: Amount of each product to produce</li>
  <li>Constraints: Resource limitations</li>
  <li>Objective: Total profit</li>
</ul>

<h3 id="2-transportation-problems">2. Transportation Problems</h3>

<p><strong>Problem:</strong> Transport goods from sources to destinations at minimum cost.</p>

<p><strong>Example:</strong> Shipping</p>
<ul>
  <li>Sources: Warehouses with supply</li>
  <li>Destinations: Stores with demand</li>
  <li>Costs: Shipping cost per unit from each source to each destination</li>
  <li>Objective: Minimize total shipping cost</li>
</ul>

<p><strong>Formulation:</strong></p>
<ul>
  <li>Variables: Amount shipped from each source to each destination</li>
  <li>Constraints: Supply limits, demand requirements</li>
  <li>Objective: Total shipping cost</li>
</ul>

<h3 id="3-network-flow-problems">3. Network Flow Problems</h3>

<p><strong>Problem:</strong> Send maximum flow through a network.</p>

<p><strong>Example:</strong> Data routing, water distribution</p>
<ul>
  <li>Network: Graph with capacities on edges</li>
  <li>Source and sink: Where flow starts and ends</li>
  <li>Objective: Maximize flow</li>
</ul>

<p><strong>Formulation:</strong></p>
<ul>
  <li>Variables: Flow on each edge</li>
  <li>Constraints: Flow conservation, capacity limits</li>
  <li>Objective: Flow from source to sink</li>
</ul>

<p><strong>Note:</strong> Specialized algorithms (Ford-Fulkerson) are faster than general LP.</p>

<h3 id="4-diet-problem">4. Diet Problem</h3>

<p><strong>Problem:</strong> Find cheapest diet meeting nutritional requirements.</p>

<p><strong>Example:</strong> Meal planning</p>
<ul>
  <li>Foods: Different foods with different nutrients and costs</li>
  <li>Requirements: Minimum amounts of each nutrient</li>
  <li>Objective: Minimize cost</li>
</ul>

<p><strong>Formulation:</strong></p>
<ul>
  <li>Variables: Amount of each food</li>
  <li>Constraints: Nutritional requirements</li>
  <li>Objective: Total cost</li>
</ul>

<h3 id="5-portfolio-optimization">5. Portfolio Optimization</h3>

<p><strong>Problem:</strong> Allocate investments to maximize return subject to risk constraints.</p>

<p><strong>Example:</strong> Financial planning</p>
<ul>
  <li>Investments: Stocks, bonds with expected returns and risks</li>
  <li>Constraints: Risk limits, budget</li>
  <li>Objective: Maximize expected return</li>
</ul>

<p><strong>Formulation:</strong></p>
<ul>
  <li>Variables: Fraction of portfolio in each investment</li>
  <li>Constraints: Risk limits, budget (sum to 1)</li>
  <li>Objective: Expected return</li>
</ul>

<h3 id="6-scheduling-problems">6. Scheduling Problems</h3>

<p><strong>Problem:</strong> Schedule tasks to minimize completion time or maximize resource utilization.</p>

<p><strong>Example:</strong> Project scheduling, workforce scheduling</p>
<ul>
  <li>Tasks: Activities with durations and resource requirements</li>
  <li>Resources: Limited resources (workers, machines)</li>
  <li>Constraints: Precedence, resource availability</li>
  <li>Objective: Minimize makespan or maximize utilization</li>
</ul>

<p><strong>Formulation:</strong></p>
<ul>
  <li>Variables: Start times or resource assignments</li>
  <li>Constraints: Precedence, resource limits</li>
  <li>Objective: Completion time or utilization</li>
</ul>

<h2 id="computational-complexity">Computational Complexity</h2>

<h3 id="polynomial-time-solvability">Polynomial-Time Solvability</h3>

<p><strong>Result:</strong> Linear Programming ∈ P</p>

<p><strong>Proof:</strong> Interior-point methods solve LP in polynomial time:</p>
<ul>
  <li>Time: O(n^{3.5} L) where L is input size</li>
  <li>Space: O(n²) for storing matrices</li>
</ul>

<p><strong>Significance:</strong> Unlike Integer Linear Programming (NP-complete), LP is efficiently solvable.</p>

<h3 id="input-size">Input Size</h3>

<p><strong>Definition:</strong> Number of bits needed to represent the input.</p>

<p><strong>Components:</strong></p>
<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Matrix A: O(mn log(max</td>
          <td>aᵢⱼ</td>
          <td>))</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Vector b: O(m log(max</td>
          <td>bᵢ</td>
          <td>))</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Vector c: O(n log(max</td>
          <td>cⱼ</td>
          <td>))</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><strong>Total:</strong> L = O(mn log(max coefficients))</p>

<h3 id="practical-performance">Practical Performance</h3>

<p><strong>Modern Solvers:</strong></p>
<ul>
  <li>Can solve problems with millions of variables and constraints</li>
  <li>Use preprocessing, advanced algorithms, parallel processing</li>
  <li>Very efficient in practice</li>
</ul>

<p><strong>Typical Performance:</strong></p>
<ul>
  <li>Small problems (&lt; 1000 variables): Milliseconds</li>
  <li>Medium problems (1000-100000 variables): Seconds to minutes</li>
  <li>Large problems (&gt; 100000 variables): Minutes to hours</li>
</ul>

<h2 id="software-and-tools">Software and Tools</h2>

<h3 id="commercial-solvers">Commercial Solvers</h3>

<p><strong>CPLEX (IBM):</strong></p>
<ul>
  <li>Industry standard</li>
  <li>Very fast and robust</li>
  <li>Good for large-scale problems</li>
</ul>

<p><strong>Gurobi:</strong></p>
<ul>
  <li>Excellent performance</li>
  <li>Good academic licenses</li>
  <li>Modern, well-documented</li>
</ul>

<p><strong>XPRESS:</strong></p>
<ul>
  <li>Commercial solver</li>
  <li>Good performance</li>
</ul>

<h3 id="open-source-solvers">Open-Source Solvers</h3>

<p><strong>GLPK (GNU Linear Programming Kit):</strong></p>
<ul>
  <li>Free and open-source</li>
  <li>Good for small to medium problems</li>
</ul>

<p><strong>CLP (COIN-OR Linear Programming):</strong></p>
<ul>
  <li>Part of COIN-OR project</li>
  <li>Free and open-source</li>
</ul>

<p><strong>HiGHS:</strong></p>
<ul>
  <li>Modern, high-performance</li>
  <li>Open-source</li>
  <li>Actively developed</li>
</ul>

<h3 id="modeling-languages-and-interfaces">Modeling Languages and Interfaces</h3>

<p><strong>Python:</strong></p>
<ul>
  <li><strong>PuLP:</strong> Simple, intuitive interface</li>
  <li><strong>CVXPY:</strong> More advanced, supports conic programming</li>
  <li><strong>OR-Tools:</strong> Google’s optimization tools</li>
</ul>

<p><strong>Julia:</strong></p>
<ul>
  <li><strong>JuMP:</strong> Mathematical modeling language</li>
  <li>Very fast and expressive</li>
</ul>

<p><strong>MATLAB:</strong></p>
<ul>
  <li><strong>linprog:</strong> Built-in LP solver</li>
  <li><strong>Optimization Toolbox:</strong> More advanced features</li>
</ul>

<p><strong>R:</strong></p>
<ul>
  <li><strong>lpSolve:</strong> R interface to lp_solve</li>
  <li><strong>Rglpk:</strong> Interface to GLPK</li>
</ul>

<h2 id="formulating-problems-as-lps">Formulating Problems as LPs</h2>

<h3 id="step-by-step-process">Step-by-Step Process</h3>

<ol>
  <li><strong>Identify Decision Variables:</strong>
    <ul>
      <li>What quantities do we need to decide?</li>
      <li>What are the units?</li>
    </ul>
  </li>
  <li><strong>Formulate Objective Function:</strong>
    <ul>
      <li>What are we trying to optimize?</li>
      <li>Is it maximize or minimize?</li>
      <li>Write as linear function of variables</li>
    </ul>
  </li>
  <li><strong>Identify Constraints:</strong>
    <ul>
      <li>What limitations exist?</li>
      <li>What relationships must hold?</li>
      <li>Write as linear inequalities or equations</li>
    </ul>
  </li>
  <li><strong>Specify Variable Domains:</strong>
    <ul>
      <li>Are variables non-negative?</li>
      <li>Are there upper bounds?</li>
    </ul>
  </li>
  <li><strong>Verify Linearity:</strong>
    <ul>
      <li>All functions must be linear</li>
      <li>No products, powers, or nonlinear functions</li>
    </ul>
  </li>
</ol>

<h3 id="common-formulation-patterns">Common Formulation Patterns</h3>

<p><strong>Pattern 1: Allocation</strong></p>
<ul>
  <li>Variables: Amount allocated to each option</li>
  <li>Constraints: Total allocation limits</li>
  <li>Objective: Maximize value or minimize cost</li>
</ul>

<p><strong>Pattern 2: Selection</strong></p>
<ul>
  <li>Variables: Binary (0-1) selection variables</li>
  <li>Constraints: Must select certain combinations</li>
  <li>Objective: Maximize value of selection</li>
</ul>

<p><strong>Pattern 3: Flow</strong></p>
<ul>
  <li>Variables: Flow on each edge/path</li>
  <li>Constraints: Flow conservation, capacity</li>
  <li>Objective: Maximize flow or minimize cost</li>
</ul>

<p><strong>Pattern 4: Assignment</strong></p>
<ul>
  <li>Variables: Assignment indicators</li>
  <li>Constraints: Each item assigned exactly once</li>
  <li>Objective: Minimize total assignment cost</li>
</ul>

<h2 id="sensitivity-analysis">Sensitivity Analysis</h2>

<p>Sensitivity analysis studies how changes in input parameters affect the optimal solution.</p>

<h3 id="shadow-prices-dual-variables">Shadow Prices (Dual Variables)</h3>

<p><strong>Definition:</strong> Rate of change in optimal objective value per unit change in right-hand side.</p>

<p><strong>Interpretation:</strong> Value of an additional unit of each resource.</p>

<p><strong>Use:</strong> Determine which resources are most valuable.</p>

<h3 id="reduced-costs">Reduced Costs</h3>

<p><strong>Definition:</strong> Rate of change in optimal objective value per unit change in objective coefficient.</p>

<p><strong>Interpretation:</strong> How much objective coefficient must change before variable enters basis.</p>

<p><strong>Use:</strong> Determine which activities are profitable.</p>

<h3 id="range-analysis">Range Analysis</h3>

<p><strong>Right-Hand Side Ranges:</strong></p>
<ul>
  <li>Range of b values for which current basis remains optimal</li>
  <li>Shows sensitivity to constraint changes</li>
</ul>

<p><strong>Objective Coefficient Ranges:</strong></p>
<ul>
  <li>Range of c values for which current solution remains optimal</li>
  <li>Shows sensitivity to objective changes</li>
</ul>

<h2 id="key-takeaways">Key Takeaways</h2>

<ol>
  <li><strong>LP is Polynomial-Time:</strong> Can be solved efficiently using interior-point methods</li>
  <li><strong>Geometric Intuition:</strong> Optimal solutions occur at vertices</li>
  <li><strong>Duality:</strong> Every LP has a dual providing bounds and insights</li>
  <li><strong>Wide Applications:</strong> Used in many real-world optimization problems</li>
  <li><strong>Formulation Skills:</strong> Key to applying LP successfully</li>
  <li><strong>Modern Solvers:</strong> Very efficient and can handle large problems</li>
  <li><strong>Foundation for Advanced Topics:</strong> Basis for Integer Programming, Approximation Algorithms</li>
</ol>

<h2 id="practice-problems">Practice Problems</h2>

<ol>
  <li>
    <p><strong>Formulate as LP:</strong> A company produces two products. Product 1 requires 2 hours of labor and 1 unit of material, sells for $10. Product 2 requires 1 hour of labor and 2 units of material, sells for $15. Available: 100 hours labor, 80 units material. Maximize profit.</p>
  </li>
  <li>
    <p><strong>Graphical Solution:</strong> Solve the LP from problem 1 graphically. Identify vertices and optimal solution.</p>
  </li>
  <li><strong>Standard Form:</strong> Convert the following to standard form:
    <ul>
      <li>Minimize: x₁ - 2x₂</li>
      <li>Subject to: x₁ + x₂ = 5, x₁ ≥ 0, x₂ unrestricted</li>
    </ul>
  </li>
  <li><strong>Dual Problem:</strong> Write the dual of:
    <ul>
      <li>Maximize: 3x₁ + 2x₂</li>
      <li>Subject to: 2x₁ + x₂ ≤ 6, x₁ + 2x₂ ≤ 8, x₁, x₂ ≥ 0</li>
    </ul>
  </li>
  <li>
    <p><strong>Simplex Method:</strong> Solve a small LP using the Simplex method manually. Show all tableaus.</p>
  </li>
  <li>
    <p><strong>Applications:</strong> Research one real-world application of LP. Formulate it as an LP problem.</p>
  </li>
  <li>
    <p><strong>Sensitivity:</strong> For a solved LP, interpret shadow prices. What do they mean in the context of the problem?</p>
  </li>
  <li><strong>Special Cases:</strong> Construct examples of:
    <ul>
      <li>Unbounded LP</li>
      <li>Infeasible LP</li>
      <li>Degenerate LP</li>
      <li>Multiple optimal solutions</li>
    </ul>
  </li>
  <li>
    <p><strong>Network Flow:</strong> Formulate a maximum flow problem as an LP. How does it differ from using specialized algorithms?</p>
  </li>
  <li><strong>Software:</strong> Use a solver (PuLP, CVXPY, or other) to solve a small LP problem. Compare with manual solution.</li>
</ol>

<h2 id="further-reading">Further Reading</h2>

<ul>
  <li><strong>Textbooks:</strong>
    <ul>
      <li>Chvátal: “Linear Programming” - Classic, comprehensive</li>
      <li>Vanderbei: “Linear Programming: Foundations and Extensions” - Modern, clear</li>
      <li>Bertsimas &amp; Tsitsiklis: “Introduction to Linear Optimization” - Rigorous</li>
    </ul>
  </li>
  <li><strong>Algorithms:</strong>
    <ul>
      <li>Dantzig: “Linear Programming and Extensions” - Original Simplex method</li>
      <li>Nesterov &amp; Nemirovskii: “Interior-Point Polynomial Algorithms” - Interior-point methods</li>
    </ul>
  </li>
  <li><strong>Applications:</strong>
    <ul>
      <li>Hillier &amp; Lieberman: “Introduction to Operations Research” - Applications focus</li>
      <li>Taha: “Operations Research” - Practical applications</li>
    </ul>
  </li>
  <li><strong>Software Documentation:</strong>
    <ul>
      <li>CPLEX, Gurobi, or other solver documentation</li>
      <li>PuLP, CVXPY, or JuMP tutorials</li>
    </ul>
  </li>
</ul>

<hr />

<p>Linear Programming is a fundamental optimization technique with wide-ranging applications. Understanding its theory, algorithms, and formulation techniques provides a strong foundation for tackling optimization problems in computer science, operations research, and many other fields. The polynomial-time solvability of LP makes it a powerful tool, while its relationship to Integer Linear Programming (through LP relaxation) connects it to NP-complete problems and approximation algorithms.</p>]]></content><author><name></name></author><category term="Algorithms" /><category term="Linear Programming" /><category term="Optimization" /><summary type="html"><![CDATA[A comprehensive introduction to Linear Programming covering problem formulation, geometric interpretation, standard forms, the Simplex method, interior-point methods, duality theory, and practical applications.]]></summary></entry><entry><title type="html">Linear Programming Fundamentals: Theory, Algorithms, and Applications</title><link href="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/linear-programming-fundamentals/" rel="alternate" type="text/html" title="Linear Programming Fundamentals: Theory, Algorithms, and Applications" /><published>2025-11-21T00:00:00+00:00</published><updated>2025-11-21T00:00:00+00:00</updated><id>https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/linear-programming-fundamentals</id><content type="html" xml:base="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/linear-programming-fundamentals/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>Linear Programming (LP) is one of the most important and widely used optimization techniques in computer science, operations research, and applied mathematics. Unlike many optimization problems that are NP-complete, Linear Programming can be solved efficiently in polynomial time, making it a powerful tool for solving real-world optimization problems. This post provides a comprehensive introduction to Linear Programming, covering its theory, algorithms, and applications.</p>

<h2 id="what-is-linear-programming">What is Linear Programming?</h2>

<p>Linear Programming is a mathematical optimization technique for finding the best outcome (maximum or minimum) of a linear objective function subject to linear equality and inequality constraints.</p>

<h3 id="problem-definition">Problem Definition</h3>

<p><strong>Linear Programming Problem:</strong></p>

<p><strong>Input:</strong></p>
<ul>
  <li>Variables: x₁, x₂, …, x_n (real numbers)</li>
  <li>Objective function: c₁x₁ + c₂x₂ + … + c_nx_n (linear)</li>
  <li>Constraints: Linear inequalities or equations</li>
  <li>Domain: Variables may be restricted (e.g., xᵢ ≥ 0)</li>
</ul>

<p><strong>Output:</strong></p>
<ul>
  <li>Values for variables that satisfy all constraints</li>
  <li>Optimize (maximize or minimize) the objective function</li>
</ul>

<h3 id="key-characteristics">Key Characteristics</h3>

<ol>
  <li><strong>Linearity:</strong> All functions (objective and constraints) are linear</li>
  <li><strong>Continuous Variables:</strong> Variables can take any real values (unlike integer programming)</li>
  <li><strong>Convexity:</strong> Feasible region is a convex polyhedron</li>
  <li><strong>Polynomial-Time Solvable:</strong> Can be solved efficiently</li>
</ol>

<h2 id="standard-forms">Standard Forms</h2>

<p>Linear Programming problems can be written in different standard forms. Understanding these forms is crucial for applying algorithms.</p>

<h3 id="standard-form-inequality-form">Standard Form (Inequality Form)</h3>

<p><strong>Maximize:</strong> c^T x</p>

<p><strong>Subject to:</strong></p>
<ul>
  <li>Ax ≤ b</li>
  <li>x ≥ 0</li>
</ul>

<p>Where:</p>
<ul>
  <li>A is an m × n matrix (constraint coefficients)</li>
  <li>b is an m-dimensional vector (right-hand side)</li>
  <li>c is an n-dimensional vector (objective coefficients)</li>
  <li>x is an n-dimensional vector (decision variables)</li>
</ul>

<h3 id="canonical-form-equality-form">Canonical Form (Equality Form)</h3>

<p><strong>Maximize:</strong> c^T x</p>

<p><strong>Subject to:</strong></p>
<ul>
  <li>Ax = b</li>
  <li>x ≥ 0</li>
</ul>

<p><strong>Conversion:</strong> Add slack variables to convert inequalities to equalities:</p>
<ul>
  <li>Constraint: a₁x₁ + a₂x₂ ≤ b becomes a₁x₁ + a₂x₂ + s = b, s ≥ 0</li>
  <li>Slack variable s represents the “slack” or unused capacity</li>
</ul>

<h3 id="general-form-conversions">General Form Conversions</h3>

<p><strong>Minimization → Maximization:</strong></p>
<ul>
  <li>Minimize c^T x ↔ Maximize -c^T x</li>
</ul>

<p><strong>Unrestricted Variables:</strong></p>
<ul>
  <li>Variable x unrestricted ↔ Replace with x = x⁺ - x⁻ where x⁺, x⁻ ≥ 0</li>
</ul>

<p><strong>≥ Constraints:</strong></p>
<ul>
  <li>a^T x ≥ b ↔ -a^T x ≤ -b</li>
</ul>

<p><strong>Equality Constraints:</strong></p>
<ul>
  <li>a^T x = b ↔ a^T x ≤ b and a^T x ≥ b</li>
</ul>

<h2 id="geometric-interpretation">Geometric Interpretation</h2>

<p>Understanding the geometry of Linear Programming provides crucial intuition.</p>

<h3 id="feasible-region">Feasible Region</h3>

<p><strong>Definition:</strong> The set of all points x that satisfy all constraints.</p>

<p><strong>Properties:</strong></p>
<ul>
  <li><strong>Convex Polyhedron:</strong> Intersection of half-spaces (from inequalities)</li>
  <li><strong>Vertices:</strong> Corner points of the polyhedron</li>
  <li><strong>Edges:</strong> Lines connecting vertices</li>
  <li><strong>Faces:</strong> Flat surfaces bounding the polyhedron</li>
</ul>

<h3 id="fundamental-theorem-of-linear-programming">Fundamental Theorem of Linear Programming</h3>

<p><strong>Theorem:</strong> If an LP has an optimal solution, then there exists an optimal solution at a vertex (extreme point) of the feasible region.</p>

<p><strong>Implications:</strong></p>
<ul>
  <li>We only need to check vertices, not all points</li>
  <li>This is why algorithms like Simplex work (they move between vertices)</li>
  <li>Number of vertices can be exponential, but algorithms are still efficient</li>
</ul>

<h3 id="example-2d-visualization">Example: 2D Visualization</h3>

<p>Consider the LP:</p>

<p><strong>Maximize:</strong> 3x₁ + 2x₂</p>

<p><strong>Subject to:</strong></p>
<ul>
  <li>2x₁ + x₂ ≤ 6</li>
  <li>x₁ + 2x₂ ≤ 8</li>
  <li>x₁, x₂ ≥ 0</li>
</ul>

<p><strong>Feasible Region:</strong></p>
<ul>
  <li>Bounded polygon (quadrilateral)</li>
  <li>Vertices: (0,0), (0,4), (4/3, 10/3), (3,0)</li>
  <li>Optimal solution: (4/3, 10/3) with value 32/3 ≈ 10.67</li>
</ul>

<p><strong>Graphical Method:</strong></p>
<ol>
  <li>Plot constraints as lines</li>
  <li>Identify feasible region (intersection of half-spaces)</li>
  <li>Plot objective function as a line</li>
  <li>Move objective line parallel to itself to find optimal vertex</li>
</ol>

<h2 id="algorithms-for-linear-programming">Algorithms for Linear Programming</h2>

<h3 id="1-simplex-method">1. Simplex Method</h3>

<p><strong>Inventor:</strong> George Dantzig (1947)</p>

<p><strong>Basic Idea:</strong> Move from vertex to vertex along edges, improving objective at each step.</p>

<p><strong>Algorithm Outline:</strong></p>
<ol>
  <li>Start at a feasible vertex (basic feasible solution)</li>
  <li>While not optimal:
    <ul>
      <li>Choose a non-basic variable to enter basis (improves objective)</li>
      <li>Choose a basic variable to leave basis (maintains feasibility)</li>
      <li>Pivot: update tableau</li>
    </ul>
  </li>
  <li>Return optimal solution</li>
</ol>

<p><strong>Key Concepts:</strong></p>
<ul>
  <li><strong>Basic Variables:</strong> Variables set to their bounds (usually 0)</li>
  <li><strong>Non-Basic Variables:</strong> Variables that can change</li>
  <li><strong>Basis:</strong> Set of basic variables</li>
  <li><strong>Tableau:</strong> Matrix representation of the LP</li>
  <li><strong>Pivoting:</strong> Moving from one basis to another</li>
</ul>

<p><strong>Advantages:</strong></p>
<ul>
  <li>Very efficient in practice</li>
  <li>Often requires O(m) to O(m+n) iterations</li>
  <li>Can handle degeneracy</li>
</ul>

<p><strong>Disadvantages:</strong></p>
<ul>
  <li>Exponential worst-case time (Klee-Minty examples)</li>
  <li>Can cycle if not careful (Bland’s rule prevents this)</li>
</ul>

<p><strong>Time Complexity:</strong></p>
<ul>
  <li><strong>Worst-case:</strong> Exponential (2^n iterations possible)</li>
  <li><strong>Average-case:</strong> Polynomial (O(m+n) iterations typical)</li>
  <li><strong>Practical:</strong> Very fast, often faster than polynomial methods</li>
</ul>

<h3 id="2-ellipsoid-method">2. Ellipsoid Method</h3>

<p><strong>Inventor:</strong> Leonid Khachiyan (1979)</p>

<p><strong>Basic Idea:</strong> Shrink an ellipsoid containing the feasible region until finding a solution.</p>

<p><strong>Algorithm Outline:</strong></p>
<ol>
  <li>Start with large ellipsoid containing feasible region</li>
  <li>While ellipsoid is large:
    <ul>
      <li>Check if center is feasible</li>
      <li>If not, use violated constraint to shrink ellipsoid</li>
      <li>Update ellipsoid</li>
    </ul>
  </li>
  <li>Return solution</li>
</ol>

<p><strong>Significance:</strong></p>
<ul>
  <li><strong>First polynomial-time algorithm</strong> for LP</li>
  <li>Proved LP ∈ P theoretically</li>
</ul>

<p><strong>Time Complexity:</strong></p>
<ul>
  <li>O(n^4 L) where L is input size (bit complexity)</li>
</ul>

<p><strong>Disadvantages:</strong></p>
<ul>
  <li>Large constants make it impractical</li>
  <li>Not used in practice</li>
</ul>

<h3 id="3-interior-point-methods">3. Interior-Point Methods</h3>

<p><strong>Inventor:</strong> Narendra Karmarkar (1984)</p>

<p><strong>Basic Idea:</strong> Move through the interior of the feasible region toward the optimal solution.</p>

<p><strong>Algorithm Outline:</strong></p>
<ol>
  <li>Start at interior point</li>
  <li>While not optimal:
    <ul>
      <li>Compute search direction (toward optimal)</li>
      <li>Choose step size (stay in interior)</li>
      <li>Update solution</li>
    </ul>
  </li>
  <li>Return optimal solution</li>
</ol>

<p><strong>Key Concepts:</strong></p>
<ul>
  <li><strong>Barrier Function:</strong> Keeps solution away from boundaries</li>
  <li><strong>Newton’s Method:</strong> Used to compute search direction</li>
  <li><strong>Path-Following:</strong> Follow central path to optimal solution</li>
</ul>

<p><strong>Advantages:</strong></p>
<ul>
  <li>Polynomial-time: O(n^{3.5} L)</li>
  <li>Practical and efficient</li>
  <li>Widely used in modern solvers</li>
</ul>

<p><strong>Time Complexity:</strong></p>
<ul>
  <li>O(n^{3.5} L) using path-following methods</li>
  <li>Typically O(√n log(1/ε)) iterations for ε-accuracy</li>
</ul>

<p><strong>Modern Variants:</strong></p>
<ul>
  <li>Primal-dual interior-point methods</li>
  <li>Predictor-corrector methods</li>
  <li>Self-dual embedding</li>
</ul>

<h3 id="4-comparison-of-methods">4. Comparison of Methods</h3>

<table>
  <thead>
    <tr>
      <th>Method</th>
      <th>Worst-Case</th>
      <th>Average-Case</th>
      <th>Practical Use</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Simplex</td>
      <td>Exponential</td>
      <td>Polynomial</td>
      <td>Very common</td>
    </tr>
    <tr>
      <td>Ellipsoid</td>
      <td>Polynomial</td>
      <td>Polynomial</td>
      <td>Rarely used</td>
    </tr>
    <tr>
      <td>Interior-Point</td>
      <td>Polynomial</td>
      <td>Polynomial</td>
      <td>Very common</td>
    </tr>
  </tbody>
</table>

<p><strong>Modern Solvers:</strong> Use combination of methods:</p>
<ul>
  <li>Simplex for warm starts</li>
  <li>Interior-point for initial solution</li>
  <li>Hybrid approaches</li>
</ul>

<h2 id="duality-theory">Duality Theory</h2>

<p>Duality is one of the most beautiful and powerful concepts in Linear Programming.</p>

<h3 id="primal-and-dual-problems">Primal and Dual Problems</h3>

<p><strong>Primal LP:</strong></p>
<ul>
  <li>Maximize c^T x</li>
  <li>Subject to Ax ≤ b, x ≥ 0</li>
</ul>

<p><strong>Dual LP:</strong></p>
<ul>
  <li>Minimize b^T y</li>
  <li>Subject to A^T y ≥ c, y ≥ 0</li>
</ul>

<p><strong>Key Relationship:</strong> Every LP has a corresponding dual LP.</p>

<h3 id="duality-theorems">Duality Theorems</h3>

<p><strong>Weak Duality Theorem:</strong></p>
<ul>
  <li>For any feasible x (primal) and y (dual): c^T x ≤ b^T y</li>
  <li>Dual provides upper bound for primal (maximization)</li>
  <li>Primal provides lower bound for dual (minimization)</li>
</ul>

<p><strong>Strong Duality Theorem:</strong></p>
<ul>
  <li>If both primal and dual have feasible solutions, then:
    <ul>
      <li>Primal optimal = Dual optimal</li>
    </ul>
  </li>
  <li>If one is unbounded, the other is infeasible</li>
  <li>If one is infeasible, the other is either infeasible or unbounded</li>
</ul>

<p><strong>Complementary Slackness:</strong></p>
<ul>
  <li>At optimality:
    <ul>
      <li>If constraint is not tight, corresponding dual variable = 0</li>
      <li>If dual constraint is not tight, corresponding primal variable = 0</li>
    </ul>
  </li>
</ul>

<h3 id="economic-interpretation">Economic Interpretation</h3>

<p><strong>Primal:</strong> Resource allocation problem</p>
<ul>
  <li>Variables: Amount of each activity</li>
  <li>Objective: Maximize profit</li>
  <li>Constraints: Resource limitations</li>
</ul>

<p><strong>Dual:</strong> Pricing problem</p>
<ul>
  <li>Variables: Prices (shadow prices) of resources</li>
  <li>Objective: Minimize total cost</li>
  <li>Constraints: Activities must be profitable</li>
</ul>

<p><strong>Shadow Prices:</strong> Dual variables represent the value of an additional unit of each resource.</p>

<h3 id="example-duality">Example: Duality</h3>

<p><strong>Primal:</strong></p>
<ul>
  <li>Maximize: 3x₁ + 2x₂</li>
  <li>Subject to: 2x₁ + x₂ ≤ 6, x₁ + 2x₂ ≤ 8, x₁, x₂ ≥ 0</li>
</ul>

<p><strong>Dual:</strong></p>
<ul>
  <li>Minimize: 6y₁ + 8y₂</li>
  <li>Subject to: 2y₁ + y₂ ≥ 3, y₁ + 2y₂ ≥ 2, y₁, y₂ ≥ 0</li>
</ul>

<p><strong>Optimal Solutions:</strong></p>
<ul>
  <li>Primal: (4/3, 10/3) with value 32/3</li>
  <li>Dual: (4/3, 1/3) with value 32/3</li>
  <li>Both have same optimal value (Strong Duality)</li>
</ul>

<h2 id="special-cases-and-degeneracy">Special Cases and Degeneracy</h2>

<h3 id="unbounded-problems">Unbounded Problems</h3>

<p><strong>Definition:</strong> Objective can be made arbitrarily large (maximization) or small (minimization).</p>

<p><strong>Causes:</strong></p>
<ul>
  <li>Feasible region is unbounded</li>
  <li>Objective direction points toward unbounded direction</li>
</ul>

<p><strong>Detection:</strong> Simplex method identifies unboundedness when no variable can leave basis.</p>

<h3 id="infeasible-problems">Infeasible Problems</h3>

<p><strong>Definition:</strong> No solution satisfies all constraints.</p>

<p><strong>Causes:</strong></p>
<ul>
  <li>Conflicting constraints</li>
  <li>Over-constrained problem</li>
</ul>

<p><strong>Detection:</strong> Phase I of Simplex method detects infeasibility.</p>

<h3 id="degeneracy">Degeneracy</h3>

<p><strong>Definition:</strong> More than m constraints are tight at a vertex (where m is number of constraints).</p>

<p><strong>Causes:</strong></p>
<ul>
  <li>Redundant constraints</li>
  <li>Special problem structure</li>
</ul>

<p><strong>Issues:</strong></p>
<ul>
  <li>Simplex may cycle (use Bland’s rule to prevent)</li>
  <li>May require extra iterations</li>
</ul>

<h3 id="multiple-optimal-solutions">Multiple Optimal Solutions</h3>

<p><strong>Definition:</strong> More than one optimal solution exists.</p>

<p><strong>Causes:</strong></p>
<ul>
  <li>Objective function parallel to a face of feasible region</li>
  <li>Entire face is optimal</li>
</ul>

<p><strong>Characterization:</strong> If x* and x** are both optimal, then any convex combination is also optimal.</p>

<h2 id="applications-of-linear-programming">Applications of Linear Programming</h2>

<h3 id="1-resource-allocation">1. Resource Allocation</h3>

<p><strong>Problem:</strong> Allocate limited resources to maximize profit or minimize cost.</p>

<p><strong>Example:</strong> Production planning</p>
<ul>
  <li>Resources: Labor, materials, machine time</li>
  <li>Products: Different products with different resource requirements</li>
  <li>Objective: Maximize profit</li>
</ul>

<p><strong>Formulation:</strong></p>
<ul>
  <li>Variables: Amount of each product to produce</li>
  <li>Constraints: Resource limitations</li>
  <li>Objective: Total profit</li>
</ul>

<h3 id="2-transportation-problems">2. Transportation Problems</h3>

<p><strong>Problem:</strong> Transport goods from sources to destinations at minimum cost.</p>

<p><strong>Example:</strong> Shipping</p>
<ul>
  <li>Sources: Warehouses with supply</li>
  <li>Destinations: Stores with demand</li>
  <li>Costs: Shipping cost per unit from each source to each destination</li>
  <li>Objective: Minimize total shipping cost</li>
</ul>

<p><strong>Formulation:</strong></p>
<ul>
  <li>Variables: Amount shipped from each source to each destination</li>
  <li>Constraints: Supply limits, demand requirements</li>
  <li>Objective: Total shipping cost</li>
</ul>

<h3 id="3-network-flow-problems">3. Network Flow Problems</h3>

<p><strong>Problem:</strong> Send maximum flow through a network.</p>

<p><strong>Example:</strong> Data routing, water distribution</p>
<ul>
  <li>Network: Graph with capacities on edges</li>
  <li>Source and sink: Where flow starts and ends</li>
  <li>Objective: Maximize flow</li>
</ul>

<p><strong>Formulation:</strong></p>
<ul>
  <li>Variables: Flow on each edge</li>
  <li>Constraints: Flow conservation, capacity limits</li>
  <li>Objective: Flow from source to sink</li>
</ul>

<p><strong>Note:</strong> Specialized algorithms (Ford-Fulkerson) are faster than general LP.</p>

<h3 id="4-diet-problem">4. Diet Problem</h3>

<p><strong>Problem:</strong> Find cheapest diet meeting nutritional requirements.</p>

<p><strong>Example:</strong> Meal planning</p>
<ul>
  <li>Foods: Different foods with different nutrients and costs</li>
  <li>Requirements: Minimum amounts of each nutrient</li>
  <li>Objective: Minimize cost</li>
</ul>

<p><strong>Formulation:</strong></p>
<ul>
  <li>Variables: Amount of each food</li>
  <li>Constraints: Nutritional requirements</li>
  <li>Objective: Total cost</li>
</ul>

<h3 id="5-portfolio-optimization">5. Portfolio Optimization</h3>

<p><strong>Problem:</strong> Allocate investments to maximize return subject to risk constraints.</p>

<p><strong>Example:</strong> Financial planning</p>
<ul>
  <li>Investments: Stocks, bonds with expected returns and risks</li>
  <li>Constraints: Risk limits, budget</li>
  <li>Objective: Maximize expected return</li>
</ul>

<p><strong>Formulation:</strong></p>
<ul>
  <li>Variables: Fraction of portfolio in each investment</li>
  <li>Constraints: Risk limits, budget (sum to 1)</li>
  <li>Objective: Expected return</li>
</ul>

<h3 id="6-scheduling-problems">6. Scheduling Problems</h3>

<p><strong>Problem:</strong> Schedule tasks to minimize completion time or maximize resource utilization.</p>

<p><strong>Example:</strong> Project scheduling, workforce scheduling</p>
<ul>
  <li>Tasks: Activities with durations and resource requirements</li>
  <li>Resources: Limited resources (workers, machines)</li>
  <li>Constraints: Precedence, resource availability</li>
  <li>Objective: Minimize makespan or maximize utilization</li>
</ul>

<p><strong>Formulation:</strong></p>
<ul>
  <li>Variables: Start times or resource assignments</li>
  <li>Constraints: Precedence, resource limits</li>
  <li>Objective: Completion time or utilization</li>
</ul>

<h2 id="computational-complexity">Computational Complexity</h2>

<h3 id="polynomial-time-solvability">Polynomial-Time Solvability</h3>

<p><strong>Result:</strong> Linear Programming ∈ P</p>

<p><strong>Proof:</strong> Interior-point methods solve LP in polynomial time:</p>
<ul>
  <li>Time: O(n^{3.5} L) where L is input size</li>
  <li>Space: O(n²) for storing matrices</li>
</ul>

<p><strong>Significance:</strong> Unlike Integer Linear Programming (NP-complete), LP is efficiently solvable.</p>

<h3 id="input-size">Input Size</h3>

<p><strong>Definition:</strong> Number of bits needed to represent the input.</p>

<p><strong>Components:</strong></p>
<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Matrix A: O(mn log(max</td>
          <td>aᵢⱼ</td>
          <td>))</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Vector b: O(m log(max</td>
          <td>bᵢ</td>
          <td>))</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Vector c: O(n log(max</td>
          <td>cⱼ</td>
          <td>))</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><strong>Total:</strong> L = O(mn log(max coefficients))</p>

<h3 id="practical-performance">Practical Performance</h3>

<p><strong>Modern Solvers:</strong></p>
<ul>
  <li>Can solve problems with millions of variables and constraints</li>
  <li>Use preprocessing, advanced algorithms, parallel processing</li>
  <li>Very efficient in practice</li>
</ul>

<p><strong>Typical Performance:</strong></p>
<ul>
  <li>Small problems (&lt; 1000 variables): Milliseconds</li>
  <li>Medium problems (1000-100000 variables): Seconds to minutes</li>
  <li>Large problems (&gt; 100000 variables): Minutes to hours</li>
</ul>

<h2 id="software-and-tools">Software and Tools</h2>

<h3 id="commercial-solvers">Commercial Solvers</h3>

<p><strong>CPLEX (IBM):</strong></p>
<ul>
  <li>Industry standard</li>
  <li>Very fast and robust</li>
  <li>Good for large-scale problems</li>
</ul>

<p><strong>Gurobi:</strong></p>
<ul>
  <li>Excellent performance</li>
  <li>Good academic licenses</li>
  <li>Modern, well-documented</li>
</ul>

<p><strong>XPRESS:</strong></p>
<ul>
  <li>Commercial solver</li>
  <li>Good performance</li>
</ul>

<h3 id="open-source-solvers">Open-Source Solvers</h3>

<p><strong>GLPK (GNU Linear Programming Kit):</strong></p>
<ul>
  <li>Free and open-source</li>
  <li>Good for small to medium problems</li>
</ul>

<p><strong>CLP (COIN-OR Linear Programming):</strong></p>
<ul>
  <li>Part of COIN-OR project</li>
  <li>Free and open-source</li>
</ul>

<p><strong>HiGHS:</strong></p>
<ul>
  <li>Modern, high-performance</li>
  <li>Open-source</li>
  <li>Actively developed</li>
</ul>

<h3 id="modeling-languages-and-interfaces">Modeling Languages and Interfaces</h3>

<p><strong>Python:</strong></p>
<ul>
  <li><strong>PuLP:</strong> Simple, intuitive interface</li>
  <li><strong>CVXPY:</strong> More advanced, supports conic programming</li>
  <li><strong>OR-Tools:</strong> Google’s optimization tools</li>
</ul>

<p><strong>Julia:</strong></p>
<ul>
  <li><strong>JuMP:</strong> Mathematical modeling language</li>
  <li>Very fast and expressive</li>
</ul>

<p><strong>MATLAB:</strong></p>
<ul>
  <li><strong>linprog:</strong> Built-in LP solver</li>
  <li><strong>Optimization Toolbox:</strong> More advanced features</li>
</ul>

<p><strong>R:</strong></p>
<ul>
  <li><strong>lpSolve:</strong> R interface to lp_solve</li>
  <li><strong>Rglpk:</strong> Interface to GLPK</li>
</ul>

<h2 id="formulating-problems-as-lps">Formulating Problems as LPs</h2>

<h3 id="step-by-step-process">Step-by-Step Process</h3>

<ol>
  <li><strong>Identify Decision Variables:</strong>
    <ul>
      <li>What quantities do we need to decide?</li>
      <li>What are the units?</li>
    </ul>
  </li>
  <li><strong>Formulate Objective Function:</strong>
    <ul>
      <li>What are we trying to optimize?</li>
      <li>Is it maximize or minimize?</li>
      <li>Write as linear function of variables</li>
    </ul>
  </li>
  <li><strong>Identify Constraints:</strong>
    <ul>
      <li>What limitations exist?</li>
      <li>What relationships must hold?</li>
      <li>Write as linear inequalities or equations</li>
    </ul>
  </li>
  <li><strong>Specify Variable Domains:</strong>
    <ul>
      <li>Are variables non-negative?</li>
      <li>Are there upper bounds?</li>
    </ul>
  </li>
  <li><strong>Verify Linearity:</strong>
    <ul>
      <li>All functions must be linear</li>
      <li>No products, powers, or nonlinear functions</li>
    </ul>
  </li>
</ol>

<h3 id="common-formulation-patterns">Common Formulation Patterns</h3>

<p><strong>Pattern 1: Allocation</strong></p>
<ul>
  <li>Variables: Amount allocated to each option</li>
  <li>Constraints: Total allocation limits</li>
  <li>Objective: Maximize value or minimize cost</li>
</ul>

<p><strong>Pattern 2: Selection</strong></p>
<ul>
  <li>Variables: Binary (0-1) selection variables</li>
  <li>Constraints: Must select certain combinations</li>
  <li>Objective: Maximize value of selection</li>
</ul>

<p><strong>Pattern 3: Flow</strong></p>
<ul>
  <li>Variables: Flow on each edge/path</li>
  <li>Constraints: Flow conservation, capacity</li>
  <li>Objective: Maximize flow or minimize cost</li>
</ul>

<p><strong>Pattern 4: Assignment</strong></p>
<ul>
  <li>Variables: Assignment indicators</li>
  <li>Constraints: Each item assigned exactly once</li>
  <li>Objective: Minimize total assignment cost</li>
</ul>

<h2 id="sensitivity-analysis">Sensitivity Analysis</h2>

<p>Sensitivity analysis studies how changes in input parameters affect the optimal solution.</p>

<h3 id="shadow-prices-dual-variables">Shadow Prices (Dual Variables)</h3>

<p><strong>Definition:</strong> Rate of change in optimal objective value per unit change in right-hand side.</p>

<p><strong>Interpretation:</strong> Value of an additional unit of each resource.</p>

<p><strong>Use:</strong> Determine which resources are most valuable.</p>

<h3 id="reduced-costs">Reduced Costs</h3>

<p><strong>Definition:</strong> Rate of change in optimal objective value per unit change in objective coefficient.</p>

<p><strong>Interpretation:</strong> How much objective coefficient must change before variable enters basis.</p>

<p><strong>Use:</strong> Determine which activities are profitable.</p>

<h3 id="range-analysis">Range Analysis</h3>

<p><strong>Right-Hand Side Ranges:</strong></p>
<ul>
  <li>Range of b values for which current basis remains optimal</li>
  <li>Shows sensitivity to constraint changes</li>
</ul>

<p><strong>Objective Coefficient Ranges:</strong></p>
<ul>
  <li>Range of c values for which current solution remains optimal</li>
  <li>Shows sensitivity to objective changes</li>
</ul>

<h2 id="key-takeaways">Key Takeaways</h2>

<ol>
  <li><strong>LP is Polynomial-Time:</strong> Can be solved efficiently using interior-point methods</li>
  <li><strong>Geometric Intuition:</strong> Optimal solutions occur at vertices</li>
  <li><strong>Duality:</strong> Every LP has a dual providing bounds and insights</li>
  <li><strong>Wide Applications:</strong> Used in many real-world optimization problems</li>
  <li><strong>Formulation Skills:</strong> Key to applying LP successfully</li>
  <li><strong>Modern Solvers:</strong> Very efficient and can handle large problems</li>
  <li><strong>Foundation for Advanced Topics:</strong> Basis for Integer Programming, Approximation Algorithms</li>
</ol>

<h2 id="practice-problems">Practice Problems</h2>

<ol>
  <li>
    <p><strong>Formulate as LP:</strong> A company produces two products. Product 1 requires 2 hours of labor and 1 unit of material, sells for $10. Product 2 requires 1 hour of labor and 2 units of material, sells for $15. Available: 100 hours labor, 80 units material. Maximize profit.</p>
  </li>
  <li>
    <p><strong>Graphical Solution:</strong> Solve the LP from problem 1 graphically. Identify vertices and optimal solution.</p>
  </li>
  <li><strong>Standard Form:</strong> Convert the following to standard form:
    <ul>
      <li>Minimize: x₁ - 2x₂</li>
      <li>Subject to: x₁ + x₂ = 5, x₁ ≥ 0, x₂ unrestricted</li>
    </ul>
  </li>
  <li><strong>Dual Problem:</strong> Write the dual of:
    <ul>
      <li>Maximize: 3x₁ + 2x₂</li>
      <li>Subject to: 2x₁ + x₂ ≤ 6, x₁ + 2x₂ ≤ 8, x₁, x₂ ≥ 0</li>
    </ul>
  </li>
  <li>
    <p><strong>Simplex Method:</strong> Solve a small LP using the Simplex method manually. Show all tableaus.</p>
  </li>
  <li>
    <p><strong>Applications:</strong> Research one real-world application of LP. Formulate it as an LP problem.</p>
  </li>
  <li>
    <p><strong>Sensitivity:</strong> For a solved LP, interpret shadow prices. What do they mean in the context of the problem?</p>
  </li>
  <li><strong>Special Cases:</strong> Construct examples of:
    <ul>
      <li>Unbounded LP</li>
      <li>Infeasible LP</li>
      <li>Degenerate LP</li>
      <li>Multiple optimal solutions</li>
    </ul>
  </li>
  <li>
    <p><strong>Network Flow:</strong> Formulate a maximum flow problem as an LP. How does it differ from using specialized algorithms?</p>
  </li>
  <li><strong>Software:</strong> Use a solver (PuLP, CVXPY, or other) to solve a small LP problem. Compare with manual solution.</li>
</ol>

<h2 id="further-reading">Further Reading</h2>

<ul>
  <li><strong>Textbooks:</strong>
    <ul>
      <li>Chvátal: “Linear Programming” - Classic, comprehensive</li>
      <li>Vanderbei: “Linear Programming: Foundations and Extensions” - Modern, clear</li>
      <li>Bertsimas &amp; Tsitsiklis: “Introduction to Linear Optimization” - Rigorous</li>
    </ul>
  </li>
  <li><strong>Algorithms:</strong>
    <ul>
      <li>Dantzig: “Linear Programming and Extensions” - Original Simplex method</li>
      <li>Nesterov &amp; Nemirovskii: “Interior-Point Polynomial Algorithms” - Interior-point methods</li>
    </ul>
  </li>
  <li><strong>Applications:</strong>
    <ul>
      <li>Hillier &amp; Lieberman: “Introduction to Operations Research” - Applications focus</li>
      <li>Taha: “Operations Research” - Practical applications</li>
    </ul>
  </li>
  <li><strong>Software Documentation:</strong>
    <ul>
      <li>CPLEX, Gurobi, or other solver documentation</li>
      <li>PuLP, CVXPY, or JuMP tutorials</li>
    </ul>
  </li>
</ul>

<hr />

<p>Linear Programming is a fundamental optimization technique with wide-ranging applications. Understanding its theory, algorithms, and formulation techniques provides a strong foundation for tackling optimization problems in computer science, operations research, and many other fields. The polynomial-time solvability of LP makes it a powerful tool, while its relationship to Integer Linear Programming (through LP relaxation) connects it to NP-complete problems and approximation algorithms.</p>]]></content><author><name></name></author><category term="Algorithms" /><category term="Linear Programming" /><category term="Optimization" /><summary type="html"><![CDATA[A comprehensive introduction to Linear Programming covering problem formulation, geometric interpretation, standard forms, the Simplex method, interior-point methods, duality theory, and practical applications.]]></summary></entry><entry><title type="html">NP-Complete Reduction Examples: How to Prove NP-Completeness</title><link href="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/np-complete-reduction-examples/" rel="alternate" type="text/html" title="NP-Complete Reduction Examples: How to Prove NP-Completeness" /><published>2025-11-21T00:00:00+00:00</published><updated>2025-11-21T00:00:00+00:00</updated><id>https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/np-complete-reduction-examples</id><content type="html" xml:base="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/np-complete-reduction-examples/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>Proving that a problem is NP-complete is a fundamental skill in computational complexity theory. The standard approach is to reduce from a known NP-complete problem (like 3-SAT) to the problem we want to prove is NP-complete. This post provides a systematic guide with detailed examples of how to construct and verify such reductions.</p>

<h2 id="understanding-np-completeness-proofs">Understanding NP-Completeness Proofs</h2>

<h3 id="the-two-step-process">The Two-Step Process</h3>

<p>To prove that a problem X is NP-complete, we need to show two things:</p>

<ol>
  <li><strong>X ∈ NP</strong>: The problem is in NP (solutions can be verified in polynomial time)</li>
  <li><strong>Y ≤ₚ X</strong>: Some known NP-complete problem Y reduces to X in polynomial time</li>
</ol>

<p>If both conditions hold, then X is NP-complete.</p>

<h3 id="why-this-works">Why This Works</h3>

<ul>
  <li>If Y ≤ₚ X and Y is NP-complete, then X is at least as hard as Y</li>
  <li>Since Y is NP-complete (hardest problems in NP), X must also be NP-complete</li>
  <li>The reduction shows that if we could solve X efficiently, we could solve Y efficiently</li>
</ul>

<h2 id="the-standard-starting-point-3-sat">The Standard Starting Point: 3-SAT</h2>

<p><strong>3-SAT</strong> (3-CNF Satisfiability) is the most commonly used starting point for reductions because:</p>

<ol>
  <li>It’s the first problem proven NP-complete (Cook-Levin Theorem)</li>
  <li>It’s conceptually simple (Boolean logic)</li>
  <li>Many problems naturally encode logical constraints</li>
</ol>

<p><strong>3-SAT Problem:</strong></p>
<ul>
  <li><strong>Input:</strong> A Boolean formula φ in 3-CNF (conjunctive normal form with exactly 3 literals per clause)</li>
  <li><strong>Output:</strong> YES if φ is satisfiable, NO otherwise</li>
</ul>

<p><strong>Example:</strong> φ = (x₁ ∨ ¬x₂ ∨ x₃) ∧ (¬x₁ ∨ x₂ ∨ x₃) ∧ (x₁ ∨ x₂ ∨ ¬x₃)</p>

<h2 id="general-strategy-for-reductions">General Strategy for Reductions</h2>

<h3 id="step-by-step-process">Step-by-Step Process</h3>

<ol>
  <li><strong>Understand the target problem</strong>: Clearly define what you’re trying to prove NP-complete</li>
  <li><strong>Design the reduction</strong>: Create a polynomial-time transformation from 3-SAT instances to instances of your problem</li>
  <li><strong>Prove correctness</strong>: Show that 3-SAT instance is satisfiable ↔ your problem instance has a solution</li>
  <li><strong>Verify polynomial time</strong>: Ensure the transformation takes polynomial time</li>
</ol>

<h3 id="key-components-of-a-reduction">Key Components of a Reduction</h3>

<p><strong>Gadgets:</strong> Small structures that encode parts of the 3-SAT instance</p>
<ul>
  <li><strong>Variable gadgets</strong>: Encode variable assignments</li>
  <li><strong>Clause gadgets</strong>: Encode clause satisfaction</li>
  <li><strong>Connections</strong>: Link gadgets to ensure consistency</li>
</ul>

<h2 id="example-1-reducing-3-sat-to-independent-set">Example 1: Reducing 3-SAT to Independent Set</h2>

<h3 id="problem-independent-set">Problem: Independent Set</h3>

<p><strong>Input:</strong> Graph G = (V, E) and integer k
<strong>Output:</strong> YES if G has an independent set of size ≥ k, NO otherwise</p>

<h3 id="reduction-construction">Reduction Construction</h3>

<p><strong>Step 1: Create Variable Gadgets</strong></p>
<ul>
  <li>For each variable xᵢ in the 3-SAT formula, create two vertices: vᵢ (representing xᵢ = TRUE) and v’ᵢ (representing xᵢ = FALSE)</li>
  <li>Connect vᵢ and v’ᵢ with an edge (ensures we can’t pick both)</li>
</ul>

<p><strong>Step 2: Create Clause Gadgets</strong></p>
<ul>
  <li>For each clause Cⱼ = (l₁ ∨ l₂ ∨ l₃), create a triangle (3 vertices connected in a cycle)</li>
  <li>Label vertices: cⱼ,₁, cⱼ,₂, cⱼ,₃ corresponding to literals l₁, l₂, l₃</li>
</ul>

<p><strong>Step 3: Connect Clause to Variable Gadgets</strong></p>
<ul>
  <li>For each clause vertex cⱼ,ᵢ representing literal l:
    <ul>
      <li>If l = xₖ, connect cⱼ,ᵢ to vₖ (if xₖ = FALSE, we can’t use this clause vertex)</li>
      <li>If l = ¬xₖ, connect cⱼ,ᵢ to v’ₖ (if xₖ = TRUE, we can’t use this clause vertex)</li>
    </ul>
  </li>
</ul>

<p><strong>Step 4: Set k = n + m</strong></p>
<ul>
  <li>n = number of variables (one from each variable pair)</li>
  <li>m = number of clauses (one from each clause triangle)</li>
</ul>

<h3 id="correctness-proof">Correctness Proof</h3>

<p><strong>Forward Direction (3-SAT satisfiable → Independent Set exists):</strong></p>
<ul>
  <li>If φ is satisfiable, pick vertices:
    <ul>
      <li>For each variable xᵢ: pick vᵢ if xᵢ = TRUE, else pick v’ᵢ</li>
      <li>For each clause Cⱼ: pick the clause vertex corresponding to a true literal</li>
    </ul>
  </li>
  <li>This gives an independent set of size n + m:
    <ul>
      <li>Variable vertices don’t conflict (we pick one per pair)</li>
      <li>Clause vertices don’t conflict (triangle edges prevent picking two from same clause)</li>
      <li>Clause vertices don’t conflict with variable vertices (by construction, if literal is true, the connection prevents conflict)</li>
    </ul>
  </li>
</ul>

<p><strong>Reverse Direction (Independent Set exists → 3-SAT satisfiable):</strong></p>
<ul>
  <li>If independent set of size n + m exists:
    <ul>
      <li>Must pick exactly one vertex from each variable pair (n vertices)</li>
      <li>Must pick exactly one vertex from each clause triangle (m vertices)</li>
    </ul>
  </li>
  <li>Set xᵢ = TRUE if vᵢ is picked, else xᵢ = FALSE</li>
  <li>Each clause has at least one true literal (the clause vertex picked corresponds to a true literal)</li>
</ul>

<p><strong>Polynomial Time:</strong></p>
<ul>
  <li>Creating graph: O(n + m) vertices, O(n + 3m + 3m) edges = O(n + m)</li>
  <li>Total: O(n + m) time</li>
</ul>

<p>Therefore, <strong>Independent Set is NP-complete</strong>.</p>

<h2 id="example-2-reducing-3-sat-to-vertex-cover">Example 2: Reducing 3-SAT to Vertex Cover</h2>

<h3 id="problem-vertex-cover">Problem: Vertex Cover</h3>

<p><strong>Input:</strong> Graph G = (V, E) and integer k
<strong>Output:</strong> YES if G has a vertex cover of size ≤ k, NO otherwise</p>

<h3 id="reduction-construction-1">Reduction Construction</h3>

<p><strong>Key Insight:</strong> Use the complement relationship with Independent Set</p>
<ul>
  <li>S is an independent set ↔ V \ S is a vertex cover</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Independent set of size ≥ k ↔ Vertex cover of size ≤</td>
          <td>V</td>
          <td>- k</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><strong>Reduction:</strong></p>
<ol>
  <li>Reduce 3-SAT to Independent Set (as above) to get graph G and k = n + m</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Return Vertex Cover instance: graph G, k’ =</td>
          <td>V</td>
          <td>- (n + m)</td>
        </tr>
      </tbody>
    </table>
  </li>
</ol>

<p><strong>Correctness:</strong></p>
<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>3-SAT satisfiable ↔ Independent set of size n + m exists ↔ Vertex cover of size</td>
          <td>V</td>
          <td>- (n + m) exists</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><strong>Polynomial Time:</strong> O(n + m)</p>

<p>Therefore, <strong>Vertex Cover is NP-complete</strong>.</p>

<h2 id="example-3-reducing-3-sat-to-clique">Example 3: Reducing 3-SAT to Clique</h2>

<h3 id="problem-clique">Problem: Clique</h3>

<p><strong>Input:</strong> Graph G = (V, E) and integer k
<strong>Output:</strong> YES if G has a clique of size ≥ k, NO otherwise</p>

<h3 id="reduction-construction-2">Reduction Construction</h3>

<p><strong>Key Insight:</strong> Use complement graph relationship</p>
<ul>
  <li>S is a clique in G ↔ S is an independent set in G̅ (complement graph)</li>
</ul>

<p><strong>Reduction:</strong></p>
<ol>
  <li>Reduce 3-SAT to Independent Set to get graph G and k = n + m</li>
  <li>Create complement graph G̅</li>
  <li>Return Clique instance: graph G̅, k = n + m</li>
</ol>

<p><strong>Correctness:</strong></p>
<ul>
  <li>3-SAT satisfiable ↔ Independent set of size n + m in G ↔ Clique of size n + m in G̅</li>
</ul>

<p><strong>Polynomial Time:</strong> O(n²) to create complement graph</p>

<p>Therefore, <strong>Clique is NP-complete</strong>.</p>

<h2 id="example-4-reducing-3-sat-to-3d-matching">Example 4: Reducing 3-SAT to 3D Matching</h2>

<h3 id="problem-3d-matching">Problem: 3D Matching</h3>

<p><strong>Input:</strong> Sets X, Y, Z and set T ⊆ X × Y × Z of triples
<strong>Output:</strong> YES if there exists a matching M ⊆ T covering all elements, NO otherwise</p>

<h3 id="reduction-construction-3">Reduction Construction</h3>

<p><strong>Step 1: Variable Gadgets</strong></p>
<ul>
  <li>For each variable xᵢ, create 2m elements in each of X, Y, Z (where m = number of clauses)</li>
  <li>Create triples connecting these elements in a chain</li>
</ul>

<p><strong>Step 2: Clause Gadgets</strong></p>
<ul>
  <li>For each clause Cⱼ, create elements that can be matched if clause is satisfied</li>
  <li>Connect to variable gadgets based on which literals appear</li>
</ul>

<p><strong>Step 3: Consistency</strong></p>
<ul>
  <li>Ensure matching covers all elements</li>
  <li>Ensure variable assignments are consistent across clauses</li>
</ul>

<p><strong>Detailed Construction:</strong></p>
<ul>
  <li>For variable xᵢ and clause Cⱼ:
    <ul>
      <li>If xᵢ appears positively in Cⱼ: create triple allowing TRUE assignment</li>
      <li>If ¬xᵢ appears in Cⱼ: create triple allowing FALSE assignment</li>
    </ul>
  </li>
  <li>Matching exists ↔ each variable has consistent assignment ↔ each clause is satisfied</li>
</ul>

<p><strong>Polynomial Time:</strong> O(nm) triples created</p>

<p>Therefore, <strong>3D Matching is NP-complete</strong>.</p>

<h2 id="example-5-reducing-3-sat-to-subset-sum">Example 5: Reducing 3-SAT to Subset Sum</h2>

<h3 id="problem-subset-sum">Problem: Subset Sum</h3>

<p><strong>Input:</strong> Set S of integers and target t
<strong>Output:</strong> YES if there exists subset S’ ⊆ S with sum exactly t, NO otherwise</p>

<h3 id="reduction-construction-4">Reduction Construction</h3>

<p><strong>Key Idea:</strong> Use numbers in base representation to encode constraints</p>

<p><strong>Step 1: Number Representation</strong></p>
<ul>
  <li>Use numbers with digits corresponding to variables and clauses</li>
  <li>Each number has n + m digits (n variables + m clauses)</li>
</ul>

<p><strong>Step 2: Variable Numbers</strong></p>
<ul>
  <li>For each variable xᵢ, create two numbers:
    <ul>
      <li>Number for xᵢ = TRUE: digit i = 1, other variable digits = 0</li>
      <li>Number for xᵢ = FALSE: digit i = 1, other variable digits = 0</li>
    </ul>
  </li>
  <li>Both have clause digits based on which clauses they satisfy</li>
</ul>

<p><strong>Step 3: Clause Numbers</strong></p>
<ul>
  <li>For each clause Cⱼ, create numbers to ensure at least one literal is true</li>
  <li>Use “slack” numbers to allow flexibility</li>
</ul>

<p><strong>Step 4: Target</strong></p>
<ul>
  <li>Target t has all variable digits = 1 (each variable assigned)</li>
  <li>All clause digits = 1 (each clause satisfied)</li>
</ul>

<p><strong>Example (simplified):</strong></p>
<ul>
  <li>Variables: x₁, x₂</li>
  <li>Clauses: (x₁ ∨ x₂), (¬x₁ ∨ x₂)</li>
  <li>Create numbers encoding assignments and clause satisfaction</li>
  <li>Target: 1111 (both variables assigned, both clauses satisfied)</li>
</ul>

<p><strong>Polynomial Time:</strong> O(nm) numbers, each with O(n + m) digits</p>

<p>Therefore, <strong>Subset Sum is NP-complete</strong>.</p>

<h2 id="common-reduction-patterns">Common Reduction Patterns</h2>

<h3 id="pattern-1-graph-problems-from-3-sat">Pattern 1: Graph Problems from 3-SAT</h3>

<p>Many graph problems use similar gadgets:</p>
<ul>
  <li><strong>Variable gadgets</strong>: Two vertices (TRUE/FALSE) connected by edge</li>
  <li><strong>Clause gadgets</strong>: Structures requiring at least one element</li>
  <li><strong>Consistency edges</strong>: Connect gadgets to enforce constraints</li>
</ul>

<p><strong>Examples:</strong> Independent Set, Vertex Cover, Clique, Dominating Set</p>

<h3 id="pattern-2-set-problems-from-3-sat">Pattern 2: Set Problems from 3-SAT</h3>

<p>Set problems often use:</p>
<ul>
  <li><strong>Variable sets</strong>: Elements representing variable assignments</li>
  <li><strong>Clause sets</strong>: Elements that must be covered</li>
  <li><strong>Intersection constraints</strong>: Ensure consistency</li>
</ul>

<p><strong>Examples:</strong> Set Cover, Exact Cover, Hitting Set</p>

<h3 id="pattern-3-optimization-problems-from-3-sat">Pattern 3: Optimization Problems from 3-SAT</h3>

<p>Optimization problems encode:</p>
<ul>
  <li><strong>Variables</strong>: Decision variables</li>
  <li><strong>Constraints</strong>: Linear or integer constraints encoding clauses</li>
  <li><strong>Objective</strong>: Often just feasibility (any solution works)</li>
</ul>

<p><strong>Examples:</strong> Integer Linear Programming, Zero-One Equations</p>

<h3 id="pattern-4-using-known-reductions">Pattern 4: Using Known Reductions</h3>

<p>Once you prove one problem NP-complete, you can reduce from it:</p>
<ul>
  <li><strong>Independent Set → Clique</strong>: Use complement graph</li>
  <li><strong>Independent Set → Vertex Cover</strong>: Use complement relationship</li>
  <li><strong>Vertex Cover → Set Cover</strong>: Encode edges as sets</li>
</ul>

<h2 id="step-by-step-reduction-template">Step-by-Step Reduction Template</h2>

<h3 id="template-for-proving-np-completeness">Template for Proving NP-Completeness</h3>

<p><strong>Step 1: Show Problem ∈ NP</strong></p>
<ul>
  <li>Describe verification algorithm</li>
  <li>Show it runs in polynomial time</li>
</ul>

<p><strong>Step 2: Choose Known NP-Complete Problem</strong></p>
<ul>
  <li>Usually 3-SAT or a closely related problem</li>
</ul>

<p><strong>Step 3: Design Reduction</strong></p>
<ul>
  <li>Describe transformation from known problem to your problem</li>
  <li>Show it’s polynomial time</li>
</ul>

<p><strong>Step 4: Prove Correctness</strong></p>
<ul>
  <li><strong>Forward</strong>: Known problem YES → Your problem YES</li>
  <li><strong>Reverse</strong>: Your problem YES → Known problem YES</li>
</ul>

<p><strong>Step 5: Verify Polynomial Time</strong></p>
<ul>
  <li>Count vertices/edges/elements created</li>
  <li>Show polynomial in input size</li>
</ul>

<h2 id="tips-for-constructing-reductions">Tips for Constructing Reductions</h2>

<h3 id="1-start-simple">1. Start Simple</h3>
<ul>
  <li>Begin with small examples (2-3 variables, 2-3 clauses)</li>
  <li>Verify your construction works manually</li>
</ul>

<h3 id="2-use-gadgets">2. Use Gadgets</h3>
<ul>
  <li>Break problem into smaller pieces</li>
  <li>Design gadgets for variables and clauses separately</li>
  <li>Connect gadgets to enforce constraints</li>
</ul>

<h3 id="3-think-about-constraints">3. Think About Constraints</h3>
<ul>
  <li>What must be true for a solution to exist?</li>
  <li>How can you encode “at least one” constraints?</li>
  <li>How can you encode “exactly one” constraints?</li>
</ul>

<h3 id="4-verify-both-directions">4. Verify Both Directions</h3>
<ul>
  <li>Don’t just show one direction</li>
  <li>Both forward and reverse are crucial</li>
</ul>

<h3 id="5-check-polynomial-time">5. Check Polynomial Time</h3>
<ul>
  <li>Count what you create</li>
  <li>Ensure it’s polynomial in input size</li>
  <li>Don’t create exponential objects</li>
</ul>

<h2 id="common-pitfalls">Common Pitfalls</h2>

<h3 id="pitfall-1-only-showing-one-direction">Pitfall 1: Only Showing One Direction</h3>
<ul>
  <li>Must prove both: Known → Your and Your → Known</li>
  <li>One direction alone doesn’t prove NP-completeness</li>
</ul>

<h3 id="pitfall-2-exponential-reduction">Pitfall 2: Exponential Reduction</h3>
<ul>
  <li>Reduction must be polynomial time</li>
  <li>Creating 2ⁿ objects makes reduction exponential</li>
</ul>

<h3 id="pitfall-3-incorrect-gadget-design">Pitfall 3: Incorrect Gadget Design</h3>
<ul>
  <li>Gadgets must correctly encode constraints</li>
  <li>Test on small examples first</li>
</ul>

<h3 id="pitfall-4-forgetting-to-show--np">Pitfall 4: Forgetting to Show ∈ NP</h3>
<ul>
  <li>Must show problem is in NP first</li>
  <li>Otherwise it could be harder than NP</li>
</ul>

<h2 id="practice-problems">Practice Problems</h2>

<ol>
  <li>
    <p><strong>Reduce 3-SAT to Hamiltonian Cycle</strong>: Design gadgets for variables and clauses. How do you ensure a cycle visits all vertices?</p>
  </li>
  <li>
    <p><strong>Reduce 3-SAT to Set Cover</strong>: Encode variables and clauses as sets. What should the universe be?</p>
  </li>
  <li>
    <p><strong>Reduce Vertex Cover to Dominating Set</strong>: Use the relationship between vertex covers and dominating sets.</p>
  </li>
  <li>
    <p><strong>Reduce 3-SAT to Partition</strong>: Encode variable assignments and clause satisfaction using subset sums.</p>
  </li>
  <li>
    <p><strong>Reduce Independent Set to Maximum Cut</strong>: Show how independent sets relate to cuts in graphs.</p>
  </li>
  <li>
    <p><strong>Reduce 3-SAT to Graph Coloring</strong>: Encode variable assignments as colors. How many colors do you need?</p>
  </li>
  <li>
    <p><strong>Prove your own reduction</strong>: Pick a problem and reduce from 3-SAT. Write out the full proof.</p>
  </li>
  <li>
    <p><strong>Chain reductions</strong>: Reduce 3-SAT → Problem A → Problem B. What does this tell you about Problem B?</p>
  </li>
</ol>

<h2 id="key-takeaways">Key Takeaways</h2>

<ol>
  <li><strong>Two-step process</strong>: Show ∈ NP and reduce from known NP-complete problem</li>
  <li><strong>3-SAT is standard</strong>: Most reductions start from 3-SAT</li>
  <li><strong>Gadgets are key</strong>: Design variable and clause gadgets carefully</li>
  <li><strong>Prove both directions</strong>: Forward and reverse correctness are essential</li>
  <li><strong>Polynomial time</strong>: Reduction must be efficient</li>
  <li><strong>Practice helps</strong>: Work through examples to develop intuition</li>
</ol>

<h2 id="reduction-summary">Reduction Summary</h2>

<p><strong>3-SAT ≤ₚ Independent Set:</strong></p>
<ul>
  <li>Variable gadgets: pairs of vertices</li>
  <li>Clause gadgets: triangles</li>
  <li>k = n + m</li>
</ul>

<p><strong>3-SAT ≤ₚ Vertex Cover:</strong></p>
<ul>
  <li>Via Independent Set complement relationship</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>k =</td>
          <td>V</td>
          <td>- (n + m)</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><strong>3-SAT ≤ₚ Clique:</strong></p>
<ul>
  <li>Via complement graph of Independent Set</li>
  <li>k = n + m</li>
</ul>

<p><strong>3-SAT ≤ₚ 3D Matching:</strong></p>
<ul>
  <li>Variable gadgets: chains of triples</li>
  <li>Clause gadgets: triples for clause satisfaction</li>
  <li>Matching covers all elements</li>
</ul>

<p><strong>3-SAT ≤ₚ Subset Sum:</strong></p>
<ul>
  <li>Base representation encoding</li>
  <li>Variable digits and clause digits</li>
  <li>Target has all 1s</li>
</ul>

<p>All reductions are polynomial-time, establishing these problems as NP-complete.</p>

<h2 id="further-reading">Further Reading</h2>

<ul>
  <li><strong>Garey &amp; Johnson</strong>: “Computers and Intractability” - Comprehensive catalog of NP-complete problems and reductions</li>
  <li><strong>Cook-Levin Theorem</strong>: Original proof that SAT is NP-complete</li>
  <li><strong>Karp’s 21 Problems</strong>: Original set of NP-complete problems and their reductions</li>
  <li><strong>Reduction Techniques</strong>: Advanced techniques like local replacement, component design, and restriction</li>
</ul>

<hr />

<p>Understanding how to construct reductions is essential for proving NP-completeness. The key is to design gadgets that correctly encode the constraints of the known NP-complete problem (like 3-SAT) into the structure of your target problem. With practice, you’ll develop intuition for which reduction techniques work best for different problem types.</p>]]></content><author><name></name></author><category term="Algorithms" /><category term="Complexity Theory" /><category term="NP-Hard" /><summary type="html"><![CDATA[A comprehensive guide to proving NP-completeness through reductions, with step-by-step examples showing how to reduce from known NP-complete problems (like 3-SAT) to prove new problems are NP-complete.]]></summary></entry><entry><title type="html">NP-Complete Reduction Reference: Using Known Problems to Prove NP-Completeness</title><link href="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/np-complete-reduction-reference/" rel="alternate" type="text/html" title="NP-Complete Reduction Reference: Using Known Problems to Prove NP-Completeness" /><published>2025-11-21T00:00:00+00:00</published><updated>2025-11-21T00:00:00+00:00</updated><id>https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/np-complete-reduction-reference</id><content type="html" xml:base="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/np-complete-reduction-reference/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>Once we have a collection of known NP-complete problems, we can use any of them as a starting point for proving new problems are NP-complete. This post provides a comprehensive reference showing which known NP-complete problems are best suited for reducing to different types of problems, along with reduction chains and examples.</p>

<h2 id="known-np-complete-problems-reference">Known NP-Complete Problems Reference</h2>

<h3 id="1-sat-boolean-satisfiability">1. SAT (Boolean Satisfiability)</h3>

<p><strong>Problem:</strong> Given a Boolean formula, is it satisfiable?</p>

<p><strong>Best for reducing to:</strong></p>
<ul>
  <li>Problems involving logical constraints</li>
  <li>Decision problems with yes/no answers</li>
  <li>Problems that naturally encode Boolean logic</li>
</ul>

<p><strong>Common reductions from SAT:</strong></p>
<ul>
  <li>SAT → 3-SAT (standard transformation)</li>
  <li>SAT → Integer Linear Programming</li>
  <li>SAT → Zero-One Equations</li>
</ul>

<h3 id="2-3-sat-3-cnf-satisfiability">2. 3-SAT (3-CNF Satisfiability)</h3>

<p><strong>Problem:</strong> Given a Boolean formula in 3-CNF, is it satisfiable?</p>

<p><strong>Best for reducing to:</strong></p>
<ul>
  <li>Graph problems (Independent Set, Vertex Cover, Clique)</li>
  <li>Set problems (Set Cover, Exact Cover)</li>
  <li>Optimization problems (ILP, ZOE)</li>
  <li>Path/cycle problems (Rudrata Path, Rudrata Cycle)</li>
</ul>

<p><strong>Why it’s popular:</strong></p>
<ul>
  <li>First problem proven NP-complete (Cook-Levin)</li>
  <li>Simple structure (variables and clauses)</li>
  <li>Easy to encode constraints</li>
</ul>

<p><strong>Common reductions from 3-SAT:</strong></p>
<ul>
  <li>3-SAT → Independent Set</li>
  <li>3-SAT → Vertex Cover</li>
  <li>3-SAT → Clique</li>
  <li>3-SAT → 3D Matching</li>
  <li>3-SAT → Subset Sum</li>
  <li>3-SAT → Integer Linear Programming</li>
  <li>3-SAT → Zero-One Equations</li>
</ul>

<h3 id="3-clique">3. Clique</h3>

<p><strong>Problem:</strong> Given graph G and integer k, does G have a clique of size ≥ k?</p>

<p><strong>Best for reducing to:</strong></p>
<ul>
  <li>Other graph problems</li>
  <li>Problems involving “all pairs” constraints</li>
  <li>Dense subgraph problems</li>
</ul>

<p><strong>Common reductions from Clique:</strong></p>
<ul>
  <li>Clique → Independent Set (via complement graph)</li>
  <li>Clique → Vertex Cover (via complement + IS relationship)</li>
  <li>Clique → Subgraph Isomorphism</li>
  <li>Clique → Maximum Common Subgraph</li>
</ul>

<p><strong>Reduction chain:</strong> 3-SAT → Independent Set → Clique</p>

<h3 id="4-independent-set-is">4. Independent Set (IS)</h3>

<p><strong>Problem:</strong> Given graph G and integer k, does G have an independent set of size ≥ k?</p>

<p><strong>Best for reducing to:</strong></p>
<ul>
  <li>Graph problems with “no edges” constraints</li>
  <li>Problems involving mutually exclusive choices</li>
  <li>Packing problems</li>
</ul>

<p><strong>Common reductions from Independent Set:</strong></p>
<ul>
  <li>Independent Set → Clique (via complement graph)</li>
  <li>Independent Set → Vertex Cover (complement relationship)</li>
  <li>Independent Set → Maximum Cut</li>
  <li>Independent Set → Graph Coloring</li>
</ul>

<p><strong>Reduction chain:</strong> 3-SAT → Independent Set</p>

<h3 id="5-vertex-cover-vc">5. Vertex Cover (VC)</h3>

<p><strong>Problem:</strong> Given graph G and integer k, does G have a vertex cover of size ≤ k?</p>

<p><strong>Best for reducing to:</strong></p>
<ul>
  <li>Covering problems</li>
  <li>Set Cover variants</li>
  <li>Dominating Set problems</li>
</ul>

<p><strong>Common reductions from Vertex Cover:</strong></p>
<ul>
  <li>Vertex Cover → Set Cover</li>
  <li>Vertex Cover → Hitting Set</li>
  <li>Vertex Cover → Dominating Set</li>
  <li>Vertex Cover → Feedback Vertex Set</li>
</ul>

<p><strong>Reduction chain:</strong> 3-SAT → Independent Set → Vertex Cover</p>

<h3 id="6-subset-sum-sss">6. Subset Sum (SSS)</h3>

<p><strong>Problem:</strong> Given set S of integers and target t, does there exist subset S’ ⊆ S with sum exactly t?</p>

<p><strong>Best for reducing to:</strong></p>
<ul>
  <li>Partition problems</li>
  <li>Knapsack variants</li>
  <li>Number problems</li>
  <li>Scheduling with constraints</li>
</ul>

<p><strong>Common reductions from Subset Sum:</strong></p>
<ul>
  <li>Subset Sum → Partition</li>
  <li>Subset Sum → Knapsack</li>
  <li>Subset Sum → Bin Packing</li>
  <li>Subset Sum → Scheduling problems</li>
</ul>

<p><strong>Reduction chain:</strong> 3-SAT → Subset Sum</p>

<h3 id="7-rudrata-path">7. Rudrata Path</h3>

<p><strong>Problem:</strong> Given graph G, does G have a path visiting every vertex exactly once?</p>

<p><strong>Best for reducing to:</strong></p>
<ul>
  <li>Path problems</li>
  <li>Routing problems</li>
  <li>Sequencing problems</li>
</ul>

<p><strong>Common reductions from Rudrata Path:</strong></p>
<ul>
  <li>Rudrata Path → Rudrata (s,t)-Path</li>
  <li>Rudrata Path → Longest Path</li>
  <li>Rudrata Path → Graph Bandwidth</li>
</ul>

<p><strong>Reduction chain:</strong> Hamiltonian Cycle → Rudrata Path</p>

<h3 id="8-rudrata-st-path">8. Rudrata (s,t)-Path</h3>

<p><strong>Problem:</strong> Given graph G and vertices s, t, does G have a path from s to t visiting every vertex exactly once?</p>

<p><strong>Best for reducing to:</strong></p>
<ul>
  <li>Constrained path problems</li>
  <li>Problems with fixed start/end points</li>
  <li>Routing with endpoints</li>
</ul>

<p><strong>Common reductions from Rudrata (s,t)-Path:</strong></p>
<ul>
  <li>Rudrata (s,t)-Path → Rudrata Path</li>
  <li>Rudrata (s,t)-Path → Longest (s,t)-Path</li>
  <li>Rudrata (s,t)-Path → Graph Traversal problems</li>
</ul>

<p><strong>Reduction chain:</strong> Hamiltonian Cycle → Rudrata (s,t)-Path → Rudrata Path</p>

<h3 id="9-rudrata-cycle-hamiltonian-cycle">9. Rudrata Cycle (Hamiltonian Cycle)</h3>

<p><strong>Problem:</strong> Given graph G, does G have a cycle visiting every vertex exactly once?</p>

<p><strong>Best for reducing to:</strong></p>
<ul>
  <li>Cycle problems</li>
  <li>TSP (unweighted version)</li>
  <li>Tour problems</li>
</ul>

<p><strong>Common reductions from Rudrata Cycle:</strong></p>
<ul>
  <li>Rudrata Cycle → Traveling Salesman Problem</li>
  <li>Rudrata Cycle → Rudrata Path</li>
  <li>Rudrata Cycle → Longest Cycle</li>
  <li>Rudrata Cycle → Graph Hamiltonicity variants</li>
</ul>

<p><strong>Reduction chain:</strong> 3-SAT → Rudrata Cycle</p>

<h3 id="10-integer-linear-programming-ilp">10. Integer Linear Programming (ILP)</h3>

<p><strong>Problem:</strong> Given linear constraints and objective, does there exist integer solution satisfying constraints?</p>

<p><strong>Best for reducing to:</strong></p>
<ul>
  <li>Optimization problems with integer constraints</li>
  <li>Scheduling problems</li>
  <li>Resource allocation problems</li>
</ul>

<p><strong>Common reductions from ILP:</strong></p>
<ul>
  <li>ILP → 0-1 ILP (Binary ILP)</li>
  <li>ILP → Knapsack</li>
  <li>ILP → Set Cover (via 0-1 ILP)</li>
  <li>ILP → Scheduling problems</li>
</ul>

<p><strong>Reduction chain:</strong> 3-SAT → Integer Linear Programming</p>

<h3 id="11-zero-one-equations-zoe">11. Zero-One Equations (ZOE)</h3>

<p><strong>Problem:</strong> Given matrix A and vector b, does there exist 0-1 vector x such that Ax = b?</p>

<p><strong>Best for reducing to:</strong></p>
<ul>
  <li>Exact cover problems</li>
  <li>Matching problems</li>
  <li>Problems with binary constraints</li>
</ul>

<p><strong>Common reductions from ZOE:</strong></p>
<ul>
  <li>ZOE → 3D Matching</li>
  <li>ZOE → Exact Cover</li>
  <li>ZOE → Set Partitioning</li>
  <li>ZOE → Integer Linear Programming</li>
</ul>

<p><strong>Reduction chain:</strong> 3-SAT → Zero-One Equations</p>

<h3 id="12-3d-matching">12. 3D Matching</h3>

<p><strong>Problem:</strong> Given sets X, Y, Z and triples T ⊆ X × Y × Z, does there exist matching covering all elements?</p>

<p><strong>Best for reducing to:</strong></p>
<ul>
  <li>Matching problems</li>
  <li>Covering problems</li>
  <li>Assignment problems</li>
</ul>

<p><strong>Common reductions from 3D Matching:</strong></p>
<ul>
  <li>3D Matching → Set Cover</li>
  <li>3D Matching → Exact Cover</li>
  <li>3D Matching → Assignment problems</li>
</ul>

<p><strong>Reduction chain:</strong> 3-SAT → 3D Matching</p>

<h3 id="13-traveling-salesman-problem-tsp">13. Traveling Salesman Problem (TSP)</h3>

<p><strong>Problem:</strong> Given complete graph with edge weights and bound B, does there exist tour of weight ≤ B?</p>

<p><strong>Best for reducing to:</strong></p>
<ul>
  <li>Routing problems</li>
  <li>Tour problems</li>
  <li>Sequencing problems with costs</li>
</ul>

<p><strong>Common reductions from TSP:</strong></p>
<ul>
  <li>TSP → Metric TSP (restriction)</li>
  <li>TSP → Vehicle Routing</li>
  <li>TSP → Job Sequencing</li>
</ul>

<p><strong>Reduction chain:</strong> Hamiltonian Cycle → TSP</p>

<h2 id="reduction-chains-and-relationships">Reduction Chains and Relationships</h2>

<h3 id="primary-chain-sat--3-sat--everything">Primary Chain: SAT → 3-SAT → Everything</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SAT
 └─→ 3-SAT
     ├─→ Independent Set
     │   ├─→ Clique (complement graph)
     │   └─→ Vertex Cover (complement relationship)
     │       └─→ Set Cover
     ├─→ 3D Matching
     │   └─→ Set Cover
     ├─→ Subset Sum
     │   ├─→ Partition
     │   └─→ Knapsack
     ├─→ Integer Linear Programming
     │   └─→ 0-1 ILP
     ├─→ Zero-One Equations
     │   └─→ 3D Matching
     └─→ Rudrata Cycle
         ├─→ Rudrata (s,t)-Path
         │   └─→ Rudrata Path
         └─→ TSP
</code></pre></div></div>

<h3 id="graph-problem-chain">Graph Problem Chain</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3-SAT
 └─→ Independent Set
     ├─→ Clique (G̅)
     └─→ Vertex Cover (V \ S)
         └─→ Dominating Set
</code></pre></div></div>

<h3 id="set-problem-chain">Set Problem Chain</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3-SAT
 └─→ 3D Matching
     └─→ Set Cover
         └─→ Hitting Set
</code></pre></div></div>

<h3 id="optimization-problem-chain">Optimization Problem Chain</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3-SAT
 └─→ Integer Linear Programming
     └─→ 0-1 ILP
         └─→ Knapsack
</code></pre></div></div>

<h2 id="choosing-the-right-starting-point">Choosing the Right Starting Point</h2>

<h3 id="use-3-sat-when">Use 3-SAT when:</h3>
<ul>
  <li>Target problem has logical constraints</li>
  <li>Need to encode “at least one” or “exactly one” constraints</li>
  <li>Problem involves choices or assignments</li>
  <li><strong>Examples:</strong> Graph problems, set problems, optimization problems</li>
</ul>

<h3 id="use-independent-set-when">Use Independent Set when:</h3>
<ul>
  <li>Target problem involves selecting non-conflicting elements</li>
  <li>Problem has “mutually exclusive” constraints</li>
  <li>Need to encode “no edges” or “no conflicts”</li>
  <li><strong>Examples:</strong> Clique, Maximum Cut, Graph Coloring</li>
</ul>

<h3 id="use-vertex-cover-when">Use Vertex Cover when:</h3>
<ul>
  <li>Target problem involves covering elements</li>
  <li>Problem has “every element must be covered” constraints</li>
  <li>Need to encode covering relationships</li>
  <li><strong>Examples:</strong> Set Cover, Hitting Set, Dominating Set</li>
</ul>

<h3 id="use-subset-sum-when">Use Subset Sum when:</h3>
<ul>
  <li>Target problem involves numbers or weights</li>
  <li>Problem has sum/total constraints</li>
  <li>Need to encode “exactly” or “at most” constraints with numbers</li>
  <li><strong>Examples:</strong> Partition, Knapsack, Bin Packing</li>
</ul>

<h3 id="use-rudrata-cyclepath-when">Use Rudrata Cycle/Path when:</h3>
<ul>
  <li>Target problem involves paths or tours</li>
  <li>Problem requires visiting all elements</li>
  <li>Need to encode ordering or sequencing</li>
  <li><strong>Examples:</strong> TSP variants, Longest Path, Graph Traversal</li>
</ul>

<h3 id="use-integer-linear-programming-when">Use Integer Linear Programming when:</h3>
<ul>
  <li>Target problem has linear constraints</li>
  <li>Problem involves optimization with integer variables</li>
  <li>Need to encode multiple constraints simultaneously</li>
  <li><strong>Examples:</strong> Scheduling, Resource Allocation, Network Design</li>
</ul>

<h3 id="use-3d-matching-when">Use 3D Matching when:</h3>
<ul>
  <li>Target problem involves matching or assignment</li>
  <li>Problem has triple constraints</li>
  <li>Need to encode “exactly one” constraints with three sets</li>
  <li><strong>Examples:</strong> Set Cover, Exact Cover, Assignment problems</li>
</ul>

<h2 id="detailed-reduction-examples">Detailed Reduction Examples</h2>

<h3 id="example-1-using-3-sat--independent-set--clique">Example 1: Using 3-SAT → Independent Set → Clique</h3>

<p><strong>Prove Clique is NP-complete:</strong></p>

<ol>
  <li>
    <p><strong>Clique ∈ NP:</strong> Given set of k vertices, verify all pairs are connected: O(k²) time</p>
  </li>
  <li><strong>Independent Set ≤ₚ Clique:</strong>
    <ul>
      <li>Given Independent Set instance: graph G, integer k</li>
      <li>Create complement graph G̅</li>
      <li>Return Clique instance: graph G̅, integer k</li>
      <li>G has independent set of size k ↔ G̅ has clique of size k</li>
    </ul>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td><strong>Polynomial time:</strong> Creating complement graph takes O(</td>
          <td>V</td>
          <td>²) time</td>
        </tr>
      </tbody>
    </table>
  </li>
</ol>

<p><strong>Therefore, Clique is NP-complete.</strong></p>

<h3 id="example-2-using-3-sat--vertex-cover--set-cover">Example 2: Using 3-SAT → Vertex Cover → Set Cover</h3>

<p><strong>Prove Set Cover is NP-complete:</strong></p>

<ol>
  <li>
    <p><strong>Set Cover ∈ NP:</strong> Given collection of sets, verify they cover universe: O(nm) time</p>
  </li>
  <li><strong>Vertex Cover ≤ₚ Set Cover:</strong>
    <ul>
      <li>Given Vertex Cover instance: graph G = (V, E), integer k</li>
      <li>Create Set Cover instance:
        <ul>
          <li>Universe U = E (all edges)</li>
          <li>For each vertex v ∈ V, create set Sᵥ = {e ∈ E : v ∈ e} (edges incident to v)</li>
          <li>k’ = k</li>
        </ul>
      </li>
      <li>G has vertex cover of size k ↔ Sets cover universe with k sets</li>
    </ul>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td><strong>Polynomial time:</strong> O(</td>
          <td>V</td>
          <td>+</td>
          <td>E</td>
          <td>) time</td>
        </tr>
      </tbody>
    </table>
  </li>
</ol>

<p><strong>Therefore, Set Cover is NP-complete.</strong></p>

<h3 id="example-3-using-3-sat--subset-sum--partition">Example 3: Using 3-SAT → Subset Sum → Partition</h3>

<p><strong>Prove Partition is NP-complete:</strong></p>

<ol>
  <li>
    <p><strong>Partition ∈ NP:</strong> Given partition, verify sums are equal: O(n) time</p>
  </li>
  <li><strong>Subset Sum ≤ₚ Partition:</strong>
    <ul>
      <li>Given Subset Sum instance: set S, target t</li>
      <li>Let T = sum of all elements in S</li>
      <li>Create Partition instance: set S’ = S ∪ {2T - t, T + t}</li>
      <li>S has subset summing to t ↔ S’ can be partitioned into equal sums</li>
      <li>If subset sums to t, partition: {subset, 2T-t} and {complement, T+t}</li>
      <li>Both sum to 2T</li>
    </ul>
  </li>
  <li><strong>Polynomial time:</strong> O(n) time</li>
</ol>

<p><strong>Therefore, Partition is NP-complete.</strong></p>

<h3 id="example-4-using-3-sat--rudrata-cycle--tsp">Example 4: Using 3-SAT → Rudrata Cycle → TSP</h3>

<p><strong>Prove TSP is NP-complete:</strong></p>

<ol>
  <li>
    <p><strong>TSP ∈ NP:</strong> Given tour, verify it visits all vertices and sum weights: O(n) time</p>
  </li>
  <li><strong>Rudrata Cycle ≤ₚ TSP:</strong>
    <ul>
      <li>Given Rudrata Cycle instance: graph G = (V, E)</li>
      <li>Create complete graph G’ with same vertices</li>
      <li>Set edge weights: w(u,v) = 1 if (u,v) ∈ E, else w(u,v) = 2</li>
      <li>
        <table>
          <tbody>
            <tr>
              <td>Set bound B =</td>
              <td>V</td>
            </tr>
          </tbody>
        </table>
      </li>
      <li>
        <table>
          <tbody>
            <tr>
              <td>G has Hamiltonian cycle ↔ G’ has TSP tour of weight</td>
              <td>V</td>
            </tr>
          </tbody>
        </table>
      </li>
    </ul>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td><strong>Polynomial time:</strong> O(</td>
          <td>V</td>
          <td>²) time</td>
        </tr>
      </tbody>
    </table>
  </li>
</ol>

<p><strong>Therefore, TSP is NP-complete.</strong></p>

<h3 id="example-5-using-3-sat--ilp--0-1-ilp">Example 5: Using 3-SAT → ILP → 0-1 ILP</h3>

<p><strong>Prove 0-1 ILP is NP-complete:</strong></p>

<ol>
  <li>
    <p><strong>0-1 ILP ∈ NP:</strong> Given 0-1 solution, verify constraints: O(mn) time</p>
  </li>
  <li><strong>ILP ≤ₚ 0-1 ILP:</strong>
    <ul>
      <li>Given ILP instance with variables xᵢ ∈ ℤ</li>
      <li>Use binary expansion: represent each xᵢ using binary variables</li>
      <li>If xᵢ ≤ M, use ⌈log₂(M+1)⌉ binary variables</li>
      <li>Convert constraints using binary representation</li>
      <li>ILP feasible ↔ 0-1 ILP feasible</li>
    </ul>
  </li>
  <li><strong>Polynomial time:</strong> O(n log M) binary variables created</li>
</ol>

<p><strong>Therefore, 0-1 ILP is NP-complete.</strong></p>

<h2 id="reduction-strategy-guide">Reduction Strategy Guide</h2>

<h3 id="strategy-1-direct-from-3-sat">Strategy 1: Direct from 3-SAT</h3>

<p><strong>When to use:</strong> Most problems, especially if they have logical structure</p>

<p><strong>Steps:</strong></p>
<ol>
  <li>Design variable gadgets (encode variable assignments)</li>
  <li>Design clause gadgets (encode clause satisfaction)</li>
  <li>Connect gadgets to enforce constraints</li>
  <li>Set parameters appropriately</li>
</ol>

<p><strong>Examples:</strong> Independent Set, Vertex Cover, 3D Matching, Subset Sum</p>

<h3 id="strategy-2-via-complementrelationship">Strategy 2: Via Complement/Relationship</h3>

<p><strong>When to use:</strong> Problems related by complement or duality</p>

<p><strong>Steps:</strong></p>
<ol>
  <li>Reduce to related problem</li>
  <li>Use complement graph or complement relationship</li>
  <li>Adjust parameters</li>
</ol>

<p><strong>Examples:</strong></p>
<ul>
  <li>Independent Set → Clique (complement graph)</li>
  <li>Independent Set → Vertex Cover (complement set)</li>
</ul>

<h3 id="strategy-3-via-restriction">Strategy 3: Via Restriction</h3>

<p><strong>When to use:</strong> Target problem is special case of known NP-complete problem</p>

<p><strong>Steps:</strong></p>
<ol>
  <li>Show target problem is restriction of known problem</li>
  <li>Show restriction is still NP-complete</li>
</ol>

<p><strong>Examples:</strong></p>
<ul>
  <li>TSP → Metric TSP (restriction to metric instances)</li>
  <li>SAT → 3-SAT (restriction to 3-CNF)</li>
</ul>

<h3 id="strategy-4-via-chain-reduction">Strategy 4: Via Chain Reduction</h3>

<p><strong>When to use:</strong> Can reduce through intermediate problems</p>

<p><strong>Steps:</strong></p>
<ol>
  <li>Reduce known problem → intermediate problem</li>
  <li>Reduce intermediate problem → target problem</li>
  <li>Compose reductions</li>
</ol>

<p><strong>Examples:</strong></p>
<ul>
  <li>3-SAT → Independent Set → Clique</li>
  <li>3-SAT → Vertex Cover → Set Cover</li>
</ul>

<h2 id="problem-specific-reduction-guides">Problem-Specific Reduction Guides</h2>

<h3 id="graph-problems">Graph Problems</h3>

<p><strong>Best starting points:</strong> 3-SAT, Independent Set, Vertex Cover, Clique</p>

<p><strong>Common patterns:</strong></p>
<ul>
  <li>Variable gadgets: pairs of vertices</li>
  <li>Clause gadgets: triangles or other structures</li>
  <li>Consistency edges: connect gadgets</li>
</ul>

<p><strong>Examples:</strong></p>
<ul>
  <li>Independent Set, Vertex Cover, Clique (from 3-SAT)</li>
  <li>Dominating Set (from Vertex Cover)</li>
  <li>Graph Coloring (from 3-SAT or Independent Set)</li>
</ul>

<h3 id="set-problems">Set Problems</h3>

<p><strong>Best starting points:</strong> 3-SAT, 3D Matching, Vertex Cover</p>

<p><strong>Common patterns:</strong></p>
<ul>
  <li>Universe: elements to cover</li>
  <li>Sets: choices or assignments</li>
  <li>Coverage: every element in at least one set</li>
</ul>

<p><strong>Examples:</strong></p>
<ul>
  <li>Set Cover (from Vertex Cover)</li>
  <li>Exact Cover (from 3D Matching or ZOE)</li>
  <li>Hitting Set (from Vertex Cover)</li>
</ul>

<h3 id="numbersum-problems">Number/Sum Problems</h3>

<p><strong>Best starting points:</strong> 3-SAT, Subset Sum</p>

<p><strong>Common patterns:</strong></p>
<ul>
  <li>Base representation encoding</li>
  <li>Digit positions for constraints</li>
  <li>Target sums for requirements</li>
</ul>

<p><strong>Examples:</strong></p>
<ul>
  <li>Subset Sum (from 3-SAT)</li>
  <li>Partition (from Subset Sum)</li>
  <li>Knapsack (from Subset Sum)</li>
</ul>

<h3 id="pathcycle-problems">Path/Cycle Problems</h3>

<p><strong>Best starting points:</strong> 3-SAT, Rudrata Cycle, Rudrata Path</p>

<p><strong>Common patterns:</strong></p>
<ul>
  <li>Variable gadgets: paths or cycles</li>
  <li>Clause gadgets: structures requiring visits</li>
  <li>Connections: enforce ordering</li>
</ul>

<p><strong>Examples:</strong></p>
<ul>
  <li>Rudrata Cycle (from 3-SAT)</li>
  <li>Rudrata Path (from Rudrata Cycle)</li>
  <li>TSP (from Rudrata Cycle)</li>
</ul>

<h3 id="optimization-problems">Optimization Problems</h3>

<p><strong>Best starting points:</strong> 3-SAT, Integer Linear Programming</p>

<p><strong>Common patterns:</strong></p>
<ul>
  <li>Variables: decision variables</li>
  <li>Constraints: linear or integer constraints</li>
  <li>Objective: feasibility or optimization</li>
</ul>

<p><strong>Examples:</strong></p>
<ul>
  <li>Integer Linear Programming (from 3-SAT)</li>
  <li>0-1 ILP (from ILP)</li>
  <li>Knapsack (from Subset Sum or ILP)</li>
</ul>

<h2 id="quick-reference-which-problem-to-use">Quick Reference: Which Problem to Use</h2>

<table>
  <thead>
    <tr>
      <th>Target Problem Type</th>
      <th>Best Starting Point</th>
      <th>Why</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Graph selection</td>
      <td>Independent Set</td>
      <td>Natural encoding of choices</td>
    </tr>
    <tr>
      <td>Graph covering</td>
      <td>Vertex Cover</td>
      <td>Direct covering structure</td>
    </tr>
    <tr>
      <td>Dense subgraphs</td>
      <td>Clique</td>
      <td>Complement of Independent Set</td>
    </tr>
    <tr>
      <td>Set covering</td>
      <td>Vertex Cover → Set Cover</td>
      <td>Natural reduction</td>
    </tr>
    <tr>
      <td>Number problems</td>
      <td>Subset Sum</td>
      <td>Base representation works well</td>
    </tr>
    <tr>
      <td>Paths/Tours</td>
      <td>Rudrata Cycle</td>
      <td>Natural path structure</td>
    </tr>
    <tr>
      <td>Matching</td>
      <td>3D Matching</td>
      <td>Triple matching structure</td>
    </tr>
    <tr>
      <td>Linear constraints</td>
      <td>Integer Linear Programming</td>
      <td>Direct constraint encoding</td>
    </tr>
    <tr>
      <td>Binary constraints</td>
      <td>Zero-One Equations</td>
      <td>0-1 structure</td>
    </tr>
    <tr>
      <td>Logical constraints</td>
      <td>3-SAT</td>
      <td>Boolean logic encoding</td>
    </tr>
  </tbody>
</table>

<h2 id="practice-construct-your-own-reductions">Practice: Construct Your Own Reductions</h2>

<h3 id="exercise-1-using-independent-set">Exercise 1: Using Independent Set</h3>
<p><strong>Prove Maximum Cut is NP-complete:</strong></p>
<ul>
  <li>Reduce from Independent Set</li>
  <li>Design: How do independent sets relate to cuts?</li>
</ul>

<h3 id="exercise-2-using-vertex-cover">Exercise 2: Using Vertex Cover</h3>
<p><strong>Prove Dominating Set is NP-complete:</strong></p>
<ul>
  <li>Reduce from Vertex Cover</li>
  <li>Design: How do vertex covers relate to dominating sets?</li>
</ul>

<h3 id="exercise-3-using-subset-sum">Exercise 3: Using Subset Sum</h3>
<p><strong>Prove Knapsack is NP-complete:</strong></p>
<ul>
  <li>Reduce from Subset Sum</li>
  <li>Design: How do subset sums relate to knapsack?</li>
</ul>

<h3 id="exercise-4-using-3d-matching">Exercise 4: Using 3D Matching</h3>
<p><strong>Prove Exact Cover is NP-complete:</strong></p>
<ul>
  <li>Reduce from 3D Matching</li>
  <li>Design: How do 3D matchings relate to exact covers?</li>
</ul>

<h3 id="exercise-5-using-tsp">Exercise 5: Using TSP</h3>
<p><strong>Prove Vehicle Routing is NP-complete:</strong></p>
<ul>
  <li>Reduce from TSP</li>
  <li>Design: How does TSP relate to vehicle routing?</li>
</ul>

<h2 id="key-takeaways">Key Takeaways</h2>

<ol>
  <li><strong>3-SAT is universal</strong>: Can reduce to almost any problem type</li>
  <li><strong>Use problem relationships</strong>: Complement graphs, set complements, etc.</li>
  <li><strong>Chain reductions</strong>: Build on known reductions</li>
  <li><strong>Choose appropriate starting point</strong>: Match problem structure</li>
  <li><strong>Practice patterns</strong>: Common gadget designs work across problems</li>
  <li><strong>Verify both directions</strong>: Forward and reverse correctness</li>
  <li><strong>Check polynomial time</strong>: Ensure reduction is efficient</li>
</ol>

<h2 id="reduction-summary-table">Reduction Summary Table</h2>

<table>
  <thead>
    <tr>
      <th>Known Problem</th>
      <th>Reduces To</th>
      <th>Method</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>3-SAT</td>
      <td>Independent Set</td>
      <td>Variable pairs + clause triangles</td>
    </tr>
    <tr>
      <td>3-SAT</td>
      <td>Vertex Cover</td>
      <td>Via Independent Set complement</td>
    </tr>
    <tr>
      <td>3-SAT</td>
      <td>Clique</td>
      <td>Via Independent Set + complement graph</td>
    </tr>
    <tr>
      <td>3-SAT</td>
      <td>Subset Sum</td>
      <td>Base representation encoding</td>
    </tr>
    <tr>
      <td>3-SAT</td>
      <td>3D Matching</td>
      <td>Variable and clause triples</td>
    </tr>
    <tr>
      <td>3-SAT</td>
      <td>ILP</td>
      <td>0-1 variables + linear constraints</td>
    </tr>
    <tr>
      <td>3-SAT</td>
      <td>ZOE</td>
      <td>Matrix equations</td>
    </tr>
    <tr>
      <td>3-SAT</td>
      <td>Rudrata Cycle</td>
      <td>Variable and clause gadgets</td>
    </tr>
    <tr>
      <td>Independent Set</td>
      <td>Clique</td>
      <td>Complement graph</td>
    </tr>
    <tr>
      <td>Independent Set</td>
      <td>Vertex Cover</td>
      <td>Complement set</td>
    </tr>
    <tr>
      <td>Vertex Cover</td>
      <td>Set Cover</td>
      <td>Edges as universe, vertices as sets</td>
    </tr>
    <tr>
      <td>Rudrata Cycle</td>
      <td>TSP</td>
      <td>Complete graph with weights 1/2</td>
    </tr>
    <tr>
      <td>Rudrata Cycle</td>
      <td>Rudrata Path</td>
      <td>Break cycle</td>
    </tr>
    <tr>
      <td>Subset Sum</td>
      <td>Partition</td>
      <td>Add balancing elements</td>
    </tr>
    <tr>
      <td>ILP</td>
      <td>0-1 ILP</td>
      <td>Binary expansion</td>
    </tr>
  </tbody>
</table>

<h2 id="further-reading">Further Reading</h2>

<ul>
  <li><strong>Garey &amp; Johnson</strong>: “Computers and Intractability” - Complete catalog of NP-complete problems</li>
  <li><strong>Karp’s 21 Problems</strong>: Original reductions establishing NP-completeness</li>
  <li><strong>Reduction Techniques</strong>: Component design, local replacement, restriction</li>
  <li><strong>Approximation Preserving Reductions</strong>: L-reductions, AP-reductions</li>
</ul>

<hr />

<p>This reference guide provides a roadmap for proving NP-completeness. By understanding which known NP-complete problems work best for different problem types, you can efficiently construct reductions and prove new problems are NP-complete. The key is matching the structure of your target problem to an appropriate starting point and designing gadgets that correctly encode the constraints.</p>]]></content><author><name></name></author><category term="Algorithms" /><category term="Complexity Theory" /><category term="NP-Hard" /><summary type="html"><![CDATA[A comprehensive reference guide showing how to use known NP-complete problems (SAT, 3-SAT, Clique, Independent Set, Vertex Cover, Subset Sum, Rudrata Path/Cycle, ILP, ZOE, 3D Matching, TSP) to prove new problems are NP-complete through reductions.]]></summary></entry><entry><title type="html">Reduction: 3-SAT to Partition</title><link href="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/reduction-3sat-to-partition/" rel="alternate" type="text/html" title="Reduction: 3-SAT to Partition" /><published>2025-11-21T00:00:00+00:00</published><updated>2025-11-21T00:00:00+00:00</updated><id>https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/reduction-3sat-to-partition</id><content type="html" xml:base="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/reduction-3sat-to-partition/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>This post provides a detailed proof that the Partition problem is NP-complete by reducing from 3-SAT. The reduction encodes variable assignments and clause satisfaction using numbers and subset sums, demonstrating how logical constraints can be represented arithmetically.</p>

<h2 id="problem-definitions">Problem Definitions</h2>

<h3 id="partition-problem">Partition Problem</h3>

<p><strong>Input:</strong> A set of integers A = {a₁, a₂, …, a_n}</p>

<p><strong>Output:</strong> YES if A can be partitioned into two subsets S₁ and S₂ such that:</p>
<ul>
  <li>S₁ ∪ S₂ = A</li>
  <li>S₁ ∩ S₂ = ∅</li>
  <li>∑<em>{a ∈ S₁} a = ∑</em>{a ∈ S₂} a</li>
</ul>

<p>NO otherwise.</p>

<h3 id="3-sat-problem">3-SAT Problem</h3>

<p><strong>Input:</strong> A Boolean formula φ in 3-CNF with:</p>
<ul>
  <li>Variables: x₁, x₂, …, x_n</li>
  <li>Clauses: C₁, C₂, …, C_m, each with exactly 3 literals</li>
</ul>

<p><strong>Output:</strong> YES if φ is satisfiable, NO otherwise.</p>

<h2 id="1-np-completeness-proof-of-partition-solution-validation">1. NP-Completeness Proof of Partition: Solution Validation</h2>

<h3 id="partition--np">Partition ∈ NP</h3>

<p><strong>Verification Algorithm:</strong>
Given a candidate solution (partition S₁, S₂):</p>
<ol>
  <li>Check that S₁ ∪ S₂ = A: O(n) time</li>
  <li>Check that S₁ ∩ S₂ = ∅: O(n) time</li>
  <li>Compute sum₁ = ∑_{a ∈ S₁} a: O(n) time</li>
  <li>Compute sum₂ = ∑_{a ∈ S₂} a: O(n) time</li>
  <li>Check if sum₁ = sum₂: O(1) time</li>
</ol>

<p><strong>Total Time:</strong> O(n), which is polynomial in input size.</p>

<p><strong>Conclusion:</strong> Partition ∈ NP.</p>

<h2 id="2-reduce-3-sat-to-partition">2. Reduce 3-SAT to Partition</h2>

<h3 id="21-input-conversion">2.1 Input Conversion</h3>

<p>Given a 3-SAT instance with n variables and m clauses, we construct a Partition instance.</p>

<p><strong>Key Idea:</strong> Use base representation to encode variable assignments and clause satisfaction.</p>

<p><strong>Construction:</strong></p>

<p><strong>Step 1: Create Variable Numbers</strong></p>
<ul>
  <li>For each variable xᵢ, create two numbers:
    <ul>
      <li><strong>vᵢ</strong>: Represents xᵢ = TRUE</li>
      <li><strong>v’ᵢ</strong>: Represents xᵢ = FALSE</li>
    </ul>
  </li>
  <li>Each number has n + m digits (base representation)</li>
  <li>Variable digits: positions 1 through n</li>
  <li>Clause digits: positions n+1 through n+m</li>
</ul>

<p><strong>Step 2: Encode Variable Assignments</strong></p>
<ul>
  <li>For variable xᵢ:
    <ul>
      <li>vᵢ has digit i = 1, all other variable digits = 0</li>
      <li>v’ᵢ has digit i = 1, all other variable digits = 0</li>
    </ul>
  </li>
  <li>This ensures exactly one of vᵢ or v’ᵢ is chosen (representing TRUE or FALSE)</li>
</ul>

<p><strong>Step 3: Encode Clause Satisfaction</strong></p>
<ul>
  <li>For clause Cⱼ and variable xᵢ:
    <ul>
      <li>If xᵢ appears positively in Cⱼ: add 1 to clause digit (n+j) of vᵢ</li>
      <li>If ¬xᵢ appears in Cⱼ: add 1 to clause digit (n+j) of v’ᵢ</li>
    </ul>
  </li>
  <li>This ensures that if a clause is satisfied, the corresponding clause digit contributes to the sum</li>
</ul>

<p><strong>Step 4: Create Clause Numbers</strong></p>
<ul>
  <li>For each clause Cⱼ, create two “slack” numbers:
    <ul>
      <li><strong>sⱼ</strong>: Has digit (n+j) = 1, all other digits = 0</li>
      <li><strong>s’ⱼ</strong>: Has digit (n+j) = 1, all other digits = 0</li>
    </ul>
  </li>
  <li>These allow flexibility in achieving the target sum</li>
</ul>

<p><strong>Step 5: Set Target</strong></p>
<ul>
  <li>Compute total sum T = sum of all numbers created</li>
  <li>Target for Partition: T/2</li>
  <li>Since we have variable numbers (2n numbers) and clause slack numbers (2m numbers), total is 2(n+m) numbers</li>
</ul>

<p><strong>Detailed Example:</strong></p>

<p>Consider 3-SAT instance:</p>
<ul>
  <li>Variables: x₁, x₂</li>
  <li>Clauses: C₁ = (x₁ ∨ ¬x₂ ∨ x₁), C₂ = (¬x₁ ∨ x₂ ∨ x₂)</li>
</ul>

<p><strong>Variable Numbers (base 10, but think in base representation):</strong></p>
<ul>
  <li>v₁ (x₁ = TRUE): digit 1 = 1, digit 3 (clause 1) = 1, digit 4 (clause 2) = 0 → value encoding</li>
  <li>v’₁ (x₁ = FALSE): digit 1 = 1, digit 3 = 0, digit 4 = 1</li>
  <li>v₂ (x₂ = TRUE): digit 2 = 1, digit 3 = 0, digit 4 = 1</li>
  <li>v’₂ (x₂ = FALSE): digit 2 = 1, digit 3 = 1, digit 4 = 0</li>
</ul>

<p><strong>Clause Slack Numbers:</strong></p>
<ul>
  <li>s₁: digit 3 = 1</li>
  <li>s’₁: digit 3 = 1</li>
  <li>s₂: digit 4 = 1</li>
  <li>s’₂: digit 4 = 1</li>
</ul>

<p><strong>Total Set:</strong> {v₁, v’₁, v₂, v’₂, s₁, s’₁, s₂, s’₂}
<strong>Target:</strong> T/2 where T = sum of all numbers</p>

<h3 id="22-output-conversion">2.2 Output Conversion</h3>

<p><strong>Given:</strong> Partition solution (S₁, S₂) where sum(S₁) = sum(S₂) = T/2</p>

<p><strong>Extract Variable Assignment:</strong></p>
<ul>
  <li>For each variable xᵢ:
    <ul>
      <li>If vᵢ ∈ S₁ (or S₂), set xᵢ = TRUE</li>
      <li>If v’ᵢ ∈ S₁ (or S₂), set xᵢ = FALSE</li>
      <li>Exactly one of vᵢ or v’ᵢ must be in each partition (by construction)</li>
    </ul>
  </li>
</ul>

<p><strong>Verify Clause Satisfaction:</strong></p>
<ul>
  <li>For each clause Cⱼ:
    <ul>
      <li>Check if at least one literal is TRUE</li>
      <li>This corresponds to clause digit (n+j) summing to at least 1 in the chosen partition</li>
    </ul>
  </li>
</ul>

<h2 id="3-correctness-justification">3. Correctness Justification</h2>

<h3 id="31-if-3-sat-has-a-solution-then-partition-has-a-solution">3.1 If 3-SAT has a solution, then Partition has a solution</h3>

<p><strong>Given:</strong> 3-SAT instance φ is satisfiable with assignment A.</p>

<p><strong>Construct Partition:</strong></p>

<p><strong>Step 1: Choose Variable Numbers</strong></p>
<ul>
  <li>For each variable xᵢ:
    <ul>
      <li>If A(xᵢ) = TRUE, put vᵢ in S₁</li>
      <li>If A(xᵢ) = FALSE, put v’ᵢ in S₁</li>
    </ul>
  </li>
  <li>Put the other variable number (v’ᵢ or vᵢ) in S₂</li>
</ul>

<p><strong>Step 2: Balance Clause Digits</strong></p>
<ul>
  <li>For each clause Cⱼ:
    <ul>
      <li>Since φ is satisfiable, at least one literal in Cⱼ is TRUE</li>
      <li>This means clause digit (n+j) has contribution ≥ 1 from variable numbers in S₁</li>
      <li>Use slack numbers sⱼ and s’ⱼ to balance:
        <ul>
          <li>If clause digit in S₁ needs more, add sⱼ to S₂</li>
          <li>If clause digit in S₂ needs more, add s’ⱼ to S₁</li>
          <li>Distribute slack numbers to achieve balance</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><strong>Step 3: Verify Balance</strong></p>
<ul>
  <li>Variable digits: Each position i has exactly one 1 in S₁ and one 1 in S₂ (balanced)</li>
  <li>Clause digits: Can be balanced using slack numbers</li>
  <li>Therefore, sum(S₁) = sum(S₂) = T/2</li>
</ul>

<p><strong>Conclusion:</strong> Partition has a solution.</p>

<h3 id="32a-if-3-sat-does-not-have-a-solution-then-partition-has-no-solution">3.2a If 3-SAT does not have a solution, then Partition has no solution</h3>

<p><strong>Given:</strong> 3-SAT instance φ is unsatisfiable.</p>

<p><strong>Proof by Contradiction:</strong></p>

<p>Assume Partition has a solution (S₁, S₂).</p>

<p><strong>Extract Assignment:</strong></p>
<ul>
  <li>For each variable xᵢ:
    <ul>
      <li>If vᵢ ∈ S₁, set xᵢ = TRUE</li>
      <li>If v’ᵢ ∈ S₁, set xᵢ = FALSE</li>
      <li>(Exactly one must be in S₁ by construction)</li>
    </ul>
  </li>
</ul>

<p><strong>Check Clause Satisfaction:</strong></p>
<ul>
  <li>For each clause Cⱼ:
    <ul>
      <li>Clause digit (n+j) must sum to the same value in S₁ and S₂</li>
      <li>Variable numbers contribute based on assignment</li>
      <li>Slack numbers can adjust, but cannot create satisfaction</li>
    </ul>
  </li>
</ul>

<p><strong>Contradiction:</strong></p>
<ul>
  <li>If φ is unsatisfiable, there exists at least one clause Cⱼ where all literals are FALSE</li>
  <li>This means clause digit (n+j) gets no contribution from variable numbers representing TRUE literals</li>
  <li>To balance, we’d need slack numbers, but this doesn’t correspond to a satisfying assignment</li>
  <li>However, the construction ensures that if clause digit balances, at least one literal must be TRUE</li>
  <li>This contradicts unsatisfiability</li>
</ul>

<p><strong>Conclusion:</strong> Partition has no solution.</p>

<h3 id="32b-if-partition-has-a-solution-then-3-sat-has-a-solution">3.2b If Partition has a solution, then 3-SAT has a solution</h3>

<p><strong>Given:</strong> Partition instance has solution (S₁, S₂) with sum(S₁) = sum(S₂) = T/2.</p>

<p><strong>Extract Variable Assignment:</strong></p>
<ul>
  <li>For each variable xᵢ:
    <ul>
      <li>Exactly one of {vᵢ, v’ᵢ} is in S₁ (by construction of numbers)</li>
      <li>If vᵢ ∈ S₁, set xᵢ = TRUE</li>
      <li>If v’ᵢ ∈ S₁, set xᵢ = FALSE</li>
    </ul>
  </li>
</ul>

<p><strong>Verify Clause Satisfaction:</strong></p>

<p><strong>For each clause Cⱼ:</strong></p>
<ul>
  <li>Clause digit (n+j) must sum to the same value in S₁ and S₂</li>
  <li>Variable numbers contribute:
    <ul>
      <li>vᵢ contributes 1 to clause digit if xᵢ appears positively in Cⱼ and vᵢ ∈ S₁</li>
      <li>v’ᵢ contributes 1 to clause digit if ¬xᵢ appears in Cⱼ and v’ᵢ ∈ S₁</li>
    </ul>
  </li>
  <li>Slack numbers sⱼ and s’ⱼ can contribute, but:
    <ul>
      <li>If clause digit in S₁ has contribution ≥ 1 from variable numbers, then at least one literal is TRUE</li>
      <li>If clause digit in S₁ has contribution 0 from variable numbers, slack must balance, but this means all literals are FALSE, which contradicts the balance requirement</li>
    </ul>
  </li>
</ul>

<p><strong>Key Insight:</strong></p>
<ul>
  <li>For clause digit (n+j) to balance:
    <ul>
      <li>If variable numbers contribute k to S₁, they contribute (total - k) to S₂</li>
      <li>Slack numbers can adjust, but cannot create satisfaction</li>
      <li>Therefore, if balance is achieved, at least one literal in each clause must be TRUE</li>
    </ul>
  </li>
</ul>

<p><strong>Conclusion:</strong> The extracted assignment satisfies all clauses, so 3-SAT has a solution.</p>

<h2 id="polynomial-time-analysis">Polynomial Time Analysis</h2>

<p><strong>Input Size:</strong></p>
<ul>
  <li>3-SAT: n variables, m clauses</li>
  <li>Partition: 2(n+m) numbers, each with O(n+m) digits</li>
</ul>

<p><strong>Construction Time:</strong></p>
<ul>
  <li>Create variable numbers: O(n(n+m)) = O(n² + nm)</li>
  <li>Create clause slack numbers: O(m(n+m)) = O(m² + nm)</li>
  <li>Total: O(n² + m² + nm) = O((n+m)²)</li>
</ul>

<p><strong>Conclusion:</strong> Reduction is polynomial-time.</p>

<h2 id="summary">Summary</h2>

<p>We have shown:</p>
<ol>
  <li><strong>Partition ∈ NP</strong>: Solutions can be verified in polynomial time</li>
  <li><strong>3-SAT ≤ₚ Partition</strong>: Polynomial-time reduction exists</li>
  <li><strong>Correctness</strong>: 3-SAT satisfiable ↔ Partition has solution</li>
</ol>

<p><strong>Therefore, Partition is NP-complete.</strong></p>

<h2 id="key-insights">Key Insights</h2>

<ol>
  <li><strong>Base Representation:</strong> Using digits to encode constraints allows arithmetic encoding of logical relationships</li>
  <li><strong>Variable Encoding:</strong> Two numbers per variable ensure exactly one assignment</li>
  <li><strong>Clause Encoding:</strong> Clause digits track which literals are satisfied</li>
  <li><strong>Slack Numbers:</strong> Provide flexibility to achieve target sum while maintaining correctness</li>
  <li><strong>Balance Requirement:</strong> The partition requirement (equal sums) enforces that all clauses are satisfied</li>
</ol>

<h2 id="practice-questions">Practice Questions</h2>

<ol>
  <li><strong>Modify the reduction</strong> to handle 2-SAT. What changes?</li>
  <li><strong>Extend the reduction</strong> to handle weighted clauses. How would you encode clause weights?</li>
  <li><strong>Analyze the base</strong> used in the reduction. What base is sufficient? Can we use base 2?</li>
  <li><strong>Prove the reverse reduction:</strong> Partition ≤ₚ Subset Sum. How does this relate?</li>
  <li><strong>Consider the numbers created.</strong> What is the maximum value? Is the reduction strongly polynomial?</li>
</ol>

<hr />

<p>This reduction demonstrates the power of arithmetic encoding in complexity theory, showing how logical constraints can be represented as numerical relationships, enabling reductions between seemingly different problem domains.</p>]]></content><author><name></name></author><category term="Algorithms" /><category term="Complexity Theory" /><category term="NP-Hard" /><summary type="html"><![CDATA[A detailed proof showing how to reduce 3-SAT to Partition, encoding variable assignments and clause satisfaction using subset sums.]]></summary></entry><entry><title type="html">Reductions from 3D Matching: Common Questions and Answers</title><link href="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/reductions-from-3d-matching/" rel="alternate" type="text/html" title="Reductions from 3D Matching: Common Questions and Answers" /><published>2025-11-21T00:00:00+00:00</published><updated>2025-11-21T00:00:00+00:00</updated><id>https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/reductions-from-3d-matching</id><content type="html" xml:base="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/reductions-from-3d-matching/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>3D Matching is a fundamental matching problem proven NP-complete by reduction from 3-SAT. This post provides answers to common reduction questions when using 3D Matching to prove other problems are NP-complete.</p>

<h2 id="problem-definition-3d-matching">Problem Definition: 3D Matching</h2>

<p><strong>3D Matching Problem:</strong></p>
<ul>
  <li><strong>Input:</strong> Sets X, Y, Z and set T ⊆ X × Y × Z of triples</li>
  <li><strong>Output:</strong> YES if there exists matching M ⊆ T covering all elements, NO otherwise</li>
</ul>

<p><strong>Perfect 3D Matching:</strong> A set of triples covering each element exactly once.</p>

<h2 id="common-reduction-questions">Common Reduction Questions</h2>

<h3 id="q1-how-do-you-reduce-3d-matching-to-set-cover">Q1: How do you reduce 3D Matching to Set Cover?</h3>

<p><strong>Answer:</strong> Encode triples as sets covering elements.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Given 3D Matching instance: sets X, Y, Z, triples T</li>
  <li>Universe U = X ∪ Y ∪ Z (all elements)</li>
  <li>For each triple t = (x, y, z) ∈ T, create set Sₜ = {x, y, z}</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Return Set Cover: universe U, sets {Sₜ : t ∈ T}, target =</td>
          <td>X</td>
          <td>=</td>
          <td>Y</td>
          <td>=</td>
          <td>Z</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Perfect 3D matching ↔ Set cover of size</td>
          <td>X</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>Matching covers all elements ↔ Sets cover universe</li>
</ul>

<table>
  <tbody>
    <tr>
      <td><strong>Time:</strong> O(</td>
      <td>T</td>
      <td>)</td>
    </tr>
  </tbody>
</table>

<h3 id="q2-how-do-you-reduce-3d-matching-to-exact-cover">Q2: How do you reduce 3D Matching to Exact Cover?</h3>

<p><strong>Answer:</strong> 3D Matching is special case of Exact Cover.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Given 3D Matching instance: sets X, Y, Z, triples T</li>
  <li>Universe U = X ∪ Y ∪ Z</li>
  <li>Sets: Each triple t becomes set Sₜ = {x, y, z}</li>
  <li>Return Exact Cover: universe U, sets {Sₜ : t ∈ T}</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>Perfect 3D matching ↔ Exact cover</li>
  <li>Each element covered exactly once</li>
</ul>

<p><strong>Time:</strong> O(1)</p>

<h3 id="q3-how-do-you-reduce-3d-matching-to-set-partitioning">Q3: How do you reduce 3D Matching to Set Partitioning?</h3>

<p><strong>Answer:</strong> Partition triples to cover all elements.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Given 3D Matching instance: sets X, Y, Z, triples T</li>
  <li>Universe U = X ∪ Y ∪ Z</li>
  <li>Sets: Each triple t becomes set Sₜ</li>
  <li>Return Set Partitioning: universe U, sets {Sₜ : t ∈ T}</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>Perfect 3D matching ↔ Set partition</li>
  <li>Partition covers all elements exactly once</li>
</ul>

<p><strong>Time:</strong> O(1)</p>

<h3 id="q4-how-do-you-reduce-3d-matching-to-assignment-problem">Q4: How do you reduce 3D Matching to Assignment Problem?</h3>

<p><strong>Answer:</strong> Encode as three-dimensional assignment.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Given 3D Matching instance: sets X, Y, Z, triples T</li>
  <li>Create Assignment Problem:
    <ul>
      <li>Three sets: X, Y, Z</li>
      <li>Assignments: Triples t = (x, y, z)</li>
      <li>Cost: 0 if t ∈ T, ∞ otherwise</li>
      <li>Target: Assign all elements</li>
    </ul>
  </li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>Perfect 3D matching ↔ Assignment covering all elements</li>
</ul>

<table>
  <tbody>
    <tr>
      <td><strong>Time:</strong> O(</td>
      <td>T</td>
      <td>)</td>
    </tr>
  </tbody>
</table>

<h3 id="q5-how-do-you-reduce-3d-matching-to-bipartite-matching">Q5: How do you reduce 3D Matching to Bipartite Matching?</h3>

<p><strong>Answer:</strong> Cannot directly (3D is harder than 2D).</p>

<p><strong>Note:</strong> 3D Matching is NP-complete, but Bipartite Matching is polynomial-time. However, can reduce to weighted matching.</p>

<p><strong>Reduction (to Weighted Matching):</strong></p>
<ul>
  <li>Given 3D Matching instance</li>
  <li>Create bipartite graph: X on left, Y×Z on right</li>
  <li>Edges: (x, (y,z)) if (x,y,z) ∈ T</li>
  <li>Weight: 1 for each edge</li>
  <li>Return: Maximum weight matching covering all of X</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>Perfect 3D matching ↔ Perfect bipartite matching</li>
</ul>

<table>
  <tbody>
    <tr>
      <td><strong>Time:</strong> O(</td>
      <td>T</td>
      <td>)</td>
    </tr>
  </tbody>
</table>

<h2 id="reduction-patterns-from-3d-matching">Reduction Patterns from 3D Matching</h2>

<h3 id="pattern-1-covering-problems">Pattern 1: Covering Problems</h3>
<ul>
  <li><strong>Use when:</strong> Target problem involves covering</li>
  <li><strong>Examples:</strong> Set Cover, Exact Cover</li>
  <li><strong>Key:</strong> Triples cover elements</li>
</ul>

<h3 id="pattern-2-partitioning">Pattern 2: Partitioning</h3>
<ul>
  <li><strong>Use when:</strong> Target problem partitions elements</li>
  <li><strong>Examples:</strong> Set Partitioning</li>
  <li><strong>Key:</strong> Each element exactly once</li>
</ul>

<h3 id="pattern-3-assignment">Pattern 3: Assignment</h3>
<ul>
  <li><strong>Use when:</strong> Target problem assigns elements</li>
  <li><strong>Examples:</strong> Assignment Problem</li>
  <li><strong>Key:</strong> Three-way assignment</li>
</ul>

<h2 id="key-takeaways">Key Takeaways</h2>

<ol>
  <li><strong>Covering structure:</strong> Natural for covering problems</li>
  <li><strong>Exact coverage:</strong> Each element exactly once</li>
  <li><strong>Triple structure:</strong> Three sets make it harder than 2D</li>
  <li><strong>Partitioning:</strong> Perfect matching = partition</li>
</ol>

<h2 id="practice-problems">Practice Problems</h2>

<ol>
  <li>Reduce 3D Matching to Hitting Set</li>
  <li>Reduce 3D Matching to Set Packing</li>
  <li>Reduce 3D Matching to Resource Allocation</li>
</ol>

<hr />

<p>3D Matching reductions often use covering and partitioning structures.</p>]]></content><author><name></name></author><category term="Algorithms" /><category term="Complexity Theory" /><category term="NP-Hard" /><summary type="html"><![CDATA[A comprehensive guide to reducing from 3D Matching to prove other problems are NP-complete, with common reduction questions and detailed answers.]]></summary></entry><entry><title type="html">Reductions from 3-SAT: Common Questions and Answers</title><link href="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/reductions-from-3sat/" rel="alternate" type="text/html" title="Reductions from 3-SAT: Common Questions and Answers" /><published>2025-11-21T00:00:00+00:00</published><updated>2025-11-21T00:00:00+00:00</updated><id>https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/reductions-from-3sat</id><content type="html" xml:base="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/reductions-from-3sat/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>3-SAT is the most commonly used starting point for NP-completeness proofs. This post provides answers to common reduction questions when using 3-SAT to prove other problems are NP-complete.</p>

<h2 id="problem-definition-3-sat">Problem Definition: 3-SAT</h2>

<p><strong>3-SAT Problem:</strong></p>
<ul>
  <li><strong>Input:</strong> A Boolean formula φ in 3-CNF (exactly 3 literals per clause)</li>
  <li><strong>Output:</strong> YES if φ is satisfiable, NO otherwise</li>
</ul>

<p><strong>Why 3-SAT is Popular:</strong></p>
<ul>
  <li>Simpler structure than general SAT</li>
  <li>Exactly 3 literals per clause simplifies gadget design</li>
  <li>Most reductions use 3-SAT as starting point</li>
</ul>

<h2 id="common-reduction-questions">Common Reduction Questions</h2>

<h3 id="q1-how-do-you-reduce-3-sat-to-independent-set">Q1: How do you reduce 3-SAT to Independent Set?</h3>

<p><strong>Answer:</strong> Create variable gadgets (pairs) and clause gadgets (triangles).</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li><strong>Variable gadgets:</strong> For each xᵢ, create vertices vᵢ (TRUE) and v’ᵢ (FALSE), connect with edge</li>
  <li><strong>Clause gadgets:</strong> For each clause, create triangle of 3 vertices (one per literal)</li>
  <li><strong>Connections:</strong> Connect clause vertex to opposite variable vertex</li>
  <li><strong>Target:</strong> k = n + m (n variables + m clauses)</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>3-SAT satisfiable ↔ Independent set of size n+m exists</li>
  <li>Pick one vertex per variable pair, one per clause triangle</li>
</ul>

<p><strong>Time:</strong> O(n + m)</p>

<h3 id="q2-how-do-you-reduce-3-sat-to-vertex-cover">Q2: How do you reduce 3-SAT to Vertex Cover?</h3>

<p><strong>Answer:</strong> Use complement relationship with Independent Set.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Reduce 3-SAT to Independent Set → graph G, k = n+m</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Return Vertex Cover: graph G, k’ =</td>
          <td>V</td>
          <td>- (n+m)</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Independent set of size n+m ↔ Vertex cover of size</td>
          <td>V</td>
          <td>- (n+m)</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><strong>Time:</strong> O(n + m)</p>

<h3 id="q3-how-do-you-reduce-3-sat-to-clique">Q3: How do you reduce 3-SAT to Clique?</h3>

<p><strong>Answer:</strong> Use complement graph of Independent Set reduction.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Reduce 3-SAT to Independent Set → graph G, k = n+m</li>
  <li>Create complement graph G̅</li>
  <li>Return Clique: graph G̅, k = n+m</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>Independent set in G ↔ Clique in G̅</li>
</ul>

<p><strong>Time:</strong> O(n²)</p>

<h3 id="q4-how-do-you-reduce-3-sat-to-subset-sum">Q4: How do you reduce 3-SAT to Subset Sum?</h3>

<p><strong>Answer:</strong> Use base representation to encode constraints.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Create numbers with n+m digits (n variables + m clauses)</li>
  <li><strong>Variable numbers:</strong> Two per variable, encode assignment</li>
  <li><strong>Clause numbers:</strong> Encode clause satisfaction</li>
  <li><strong>Target:</strong> Sum encoding all variables assigned and all clauses satisfied</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>3-SAT satisfiable ↔ Subset sums to target</li>
  <li>Digits encode variable assignments and clause satisfaction</li>
</ul>

<p><strong>Time:</strong> O(nm)</p>

<h3 id="q5-how-do-you-reduce-3-sat-to-3d-matching">Q5: How do you reduce 3-SAT to 3D Matching?</h3>

<p><strong>Answer:</strong> Create variable gadgets (chains) and clause gadgets (triples).</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li><strong>Variable gadgets:</strong> For each xᵢ, create chain of triples</li>
  <li><strong>Clause gadgets:</strong> For each clause, create triples connecting to variable gadgets</li>
  <li><strong>Matching:</strong> Covers all elements ↔ consistent assignment + satisfied clauses</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>3-SAT satisfiable ↔ Perfect 3D matching exists</li>
  <li>Matching enforces variable consistency and clause satisfaction</li>
</ul>

<p><strong>Time:</strong> O(nm)</p>

<h3 id="q6-how-do-you-reduce-3-sat-to-integer-linear-programming">Q6: How do you reduce 3-SAT to Integer Linear Programming?</h3>

<p><strong>Answer:</strong> Encode variables as 0-1 variables and clauses as constraints.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>For each xᵢ, create variable xᵢ ∈ {0,1}</li>
  <li>For clause (l₁ ∨ l₂ ∨ l₃):
    <ul>
      <li>If lⱼ = xₖ, use xₖ</li>
      <li>If lⱼ = ¬xₖ, use (1 - xₖ)</li>
      <li>Constraint: l₁ + l₂ + l₃ ≥ 1</li>
    </ul>
  </li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>3-SAT satisfiable ↔ ILP feasible</li>
  <li>Each clause requires at least one TRUE literal</li>
</ul>

<p><strong>Time:</strong> O(n + m)</p>

<h3 id="q7-how-do-you-reduce-3-sat-to-zero-one-equations">Q7: How do you reduce 3-SAT to Zero-One Equations?</h3>

<p><strong>Answer:</strong> Convert to system of equations over GF(2).</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>For each variable xᵢ, create xᵢ ∈ {0,1}</li>
  <li>For clause (l₁ ∨ l₂ ∨ l₃):
    <ul>
      <li>Equation: l₁ + l₂ + l₃ = 1 (mod 2)</li>
      <li>Use xᵢ for positive, (1 - xᵢ) for negative</li>
    </ul>
  </li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>3-SAT satisfiable ↔ ZOE has solution</li>
  <li>Exactly one literal TRUE per clause (mod 2)</li>
</ul>

<p><strong>Time:</strong> O(nm)</p>

<h3 id="q8-how-do-you-reduce-3-sat-to-rudrata-cycle">Q8: How do you reduce 3-SAT to Rudrata Cycle?</h3>

<p><strong>Answer:</strong> Create variable gadgets (paths) and clause gadgets (requiring visits).</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li><strong>Variable gadgets:</strong> For each xᵢ, create path with two routes (TRUE/FALSE)</li>
  <li><strong>Clause gadgets:</strong> For each clause, create vertices that must be visited</li>
  <li><strong>Connections:</strong> Link gadgets to enforce consistency</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>3-SAT satisfiable ↔ Hamiltonian cycle exists</li>
  <li>Cycle encodes variable assignment and clause satisfaction</li>
</ul>

<p><strong>Time:</strong> O(n²m)</p>

<h3 id="q9-how-do-you-reduce-3-sat-to-traveling-salesman-problem">Q9: How do you reduce 3-SAT to Traveling Salesman Problem?</h3>

<p><strong>Answer:</strong> Reduce via Rudrata Cycle.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Reduce 3-SAT to Rudrata Cycle → graph G</li>
  <li>Create complete graph with weights:
    <ul>
      <li>Weight 1 if edge exists in G</li>
      <li>Weight 2 if edge doesn’t exist</li>
    </ul>
  </li>
  <li>Target: n (number of vertices)</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>Rudrata cycle exists ↔ TSP tour of weight n exists</li>
</ul>

<p><strong>Time:</strong> O(n²)</p>

<h3 id="q10-how-do-you-reduce-3-sat-to-set-cover">Q10: How do you reduce 3-SAT to Set Cover?</h3>

<p><strong>Answer:</strong> Encode variables and clauses as sets.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Universe: All clauses</li>
  <li>For each variable xᵢ:
    <ul>
      <li>Set Sᵢ: Clauses where xᵢ appears positively</li>
      <li>Set S’ᵢ: Clauses where ¬xᵢ appears</li>
    </ul>
  </li>
  <li>Target: Cover all clauses with n sets</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>3-SAT satisfiable ↔ Set Cover of size n exists</li>
  <li>Each clause covered by satisfied literal’s set</li>
</ul>

<p><strong>Time:</strong> O(nm)</p>

<h2 id="reduction-patterns-from-3-sat">Reduction Patterns from 3-SAT</h2>

<h3 id="pattern-1-graph-problems">Pattern 1: Graph Problems</h3>
<ul>
  <li><strong>Variable gadgets:</strong> Pairs of vertices (TRUE/FALSE)</li>
  <li><strong>Clause gadgets:</strong> Triangles or other structures</li>
  <li><strong>Examples:</strong> Independent Set, Vertex Cover, Clique</li>
</ul>

<h3 id="pattern-2-number-problems">Pattern 2: Number Problems</h3>
<ul>
  <li><strong>Base representation:</strong> Digits encode constraints</li>
  <li><strong>Variable encoding:</strong> Numbers represent assignments</li>
  <li><strong>Examples:</strong> Subset Sum, Partition</li>
</ul>

<h3 id="pattern-3-set-problems">Pattern 3: Set Problems</h3>
<ul>
  <li><strong>Universe:</strong> Clauses or elements</li>
  <li><strong>Sets:</strong> Variable assignments or choices</li>
  <li><strong>Examples:</strong> Set Cover, Exact Cover, 3D Matching</li>
</ul>

<h3 id="pattern-4-constraint-problems">Pattern 4: Constraint Problems</h3>
<ul>
  <li><strong>Variables:</strong> Direct mapping</li>
  <li><strong>Constraints:</strong> Clause requirements</li>
  <li><strong>Examples:</strong> ILP, ZOE, Graph Coloring</li>
</ul>

<h2 id="key-takeaways">Key Takeaways</h2>

<ol>
  <li><strong>3-SAT is standard:</strong> Most reductions start from 3-SAT</li>
  <li><strong>Gadget design:</strong> Variable gadgets + clause gadgets</li>
  <li><strong>Consistency:</strong> Ensure variable assignments are consistent</li>
  <li><strong>Satisfaction:</strong> Ensure all clauses are satisfied</li>
  <li><strong>Polynomial time:</strong> Most reductions are efficient</li>
</ol>

<h2 id="practice-problems">Practice Problems</h2>

<ol>
  <li>Reduce 3-SAT to Dominating Set</li>
  <li>Reduce 3-SAT to Graph Coloring</li>
  <li>Reduce 3-SAT to Longest Path</li>
  <li>Reduce 3-SAT to Knapsack</li>
  <li>Reduce 3-SAT to Bin Packing</li>
</ol>

<hr />

<p>3-SAT is the workhorse of NP-completeness proofs, and mastering reductions from 3-SAT is essential for complexity theory.</p>]]></content><author><name></name></author><category term="Algorithms" /><category term="Complexity Theory" /><category term="NP-Hard" /><summary type="html"><![CDATA[A comprehensive guide to reducing from 3-SAT to prove other problems are NP-complete, with common reduction questions and detailed answers.]]></summary></entry><entry><title type="html">Reductions from Clique: Common Questions and Answers</title><link href="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/reductions-from-clique/" rel="alternate" type="text/html" title="Reductions from Clique: Common Questions and Answers" /><published>2025-11-21T00:00:00+00:00</published><updated>2025-11-21T00:00:00+00:00</updated><id>https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/reductions-from-clique</id><content type="html" xml:base="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/reductions-from-clique/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>Clique is a fundamental graph problem that’s NP-complete. This post provides answers to common reduction questions when using Clique to prove other problems are NP-complete.</p>

<h2 id="problem-definition-clique">Problem Definition: Clique</h2>

<p><strong>Clique Problem:</strong></p>
<ul>
  <li><strong>Input:</strong> Graph G = (V, E) and integer k</li>
  <li><strong>Output:</strong> YES if G has a clique of size ≥ k, NO otherwise</li>
</ul>

<p><strong>Clique:</strong> A subset of vertices where every pair is connected by an edge.</p>

<h2 id="common-reduction-questions">Common Reduction Questions</h2>

<h3 id="q1-how-do-you-reduce-clique-to-independent-set">Q1: How do you reduce Clique to Independent Set?</h3>

<p><strong>Answer:</strong> Use complement graph.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Given Clique instance: graph G, integer k</li>
  <li>Create complement graph G̅ (edge exists in G̅ ↔ edge doesn’t exist in G)</li>
  <li>Return Independent Set: graph G̅, integer k</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>Clique of size k in G ↔ Independent set of size k in G̅</li>
  <li>No edges in G̅ ↔ all edges in G</li>
</ul>

<p><strong>Time:</strong> O(n²) to create complement</p>

<h3 id="q2-how-do-you-reduce-clique-to-vertex-cover">Q2: How do you reduce Clique to Vertex Cover?</h3>

<p><strong>Answer:</strong> Use complement graph + complement relationship.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Reduce Clique to Independent Set → graph G̅, k</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Return Vertex Cover: graph G̅, k’ =</td>
          <td>V</td>
          <td>- k</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Clique of size k in G ↔ Independent set of size k in G̅ ↔ Vertex cover of size</td>
          <td>V</td>
          <td>- k in G̅</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><strong>Time:</strong> O(n²)</p>

<h3 id="q3-how-do-you-reduce-clique-to-subgraph-isomorphism">Q3: How do you reduce Clique to Subgraph Isomorphism?</h3>

<p><strong>Answer:</strong> Check if complete graph Kₖ is subgraph of G.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Given Clique instance: graph G, integer k</li>
  <li>Create complete graph Kₖ (clique of size k)</li>
  <li>Return Subgraph Isomorphism: graph G, pattern Kₖ</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>Clique of size k in G ↔ Kₖ is subgraph of G</li>
</ul>

<p><strong>Time:</strong> O(1) (trivial reduction)</p>

<h3 id="q4-how-do-you-reduce-clique-to-maximum-common-subgraph">Q4: How do you reduce Clique to Maximum Common Subgraph?</h3>

<p><strong>Answer:</strong> Find common subgraph with another complete graph.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Given Clique instance: graph G, integer k</li>
  <li>Create complete graph Kₖ</li>
  <li>Return Maximum Common Subgraph: graphs G and Kₖ, target size k</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>Clique of size k in G ↔ Common subgraph of size k exists</li>
</ul>

<p><strong>Time:</strong> O(1)</p>

<h3 id="q5-how-do-you-reduce-clique-to-dense-subgraph">Q5: How do you reduce Clique to Dense Subgraph?</h3>

<p><strong>Answer:</strong> Clique is special case of dense subgraph.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Given Clique instance: graph G, integer k</li>
  <li>Return Dense Subgraph: graph G, size k, density threshold = 1.0 (complete)</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>Clique of size k ↔ Dense subgraph with density 1.0</li>
</ul>

<p><strong>Time:</strong> O(1)</p>

<h2 id="reduction-patterns-from-clique">Reduction Patterns from Clique</h2>

<h3 id="pattern-1-complement-graph">Pattern 1: Complement Graph</h3>
<ul>
  <li><strong>Use when:</strong> Target problem is complement of clique-like structure</li>
  <li><strong>Examples:</strong> Independent Set, Vertex Cover</li>
  <li><strong>Key:</strong> Complement graph preserves structure</li>
</ul>

<h3 id="pattern-2-subgraph-problems">Pattern 2: Subgraph Problems</h3>
<ul>
  <li><strong>Use when:</strong> Target problem involves finding subgraphs</li>
  <li><strong>Examples:</strong> Subgraph Isomorphism, Maximum Common Subgraph</li>
  <li><strong>Key:</strong> Clique is complete subgraph</li>
</ul>

<h3 id="pattern-3-restriction">Pattern 3: Restriction</h3>
<ul>
  <li><strong>Use when:</strong> Target problem is generalization</li>
  <li><strong>Examples:</strong> Dense Subgraph, k-Clique</li>
  <li><strong>Key:</strong> Clique is special case</li>
</ul>

<h2 id="key-takeaways">Key Takeaways</h2>

<ol>
  <li><strong>Complement graph:</strong> Powerful tool for graph reductions</li>
  <li><strong>Complete subgraphs:</strong> Clique represents perfect connectivity</li>
  <li><strong>Subgraph problems:</strong> Many reduce from Clique</li>
  <li><strong>Restriction:</strong> Clique is special case of many problems</li>
</ol>

<h2 id="practice-problems">Practice Problems</h2>

<ol>
  <li>Reduce Clique to k-Clique (fixed k)</li>
  <li>Reduce Clique to Maximum Clique</li>
  <li>Reduce Clique to Clique Cover</li>
  <li>Reduce Clique to Partition into Cliques</li>
</ol>

<hr />

<p>Clique reductions often use complement graphs and subgraph relationships.</p>]]></content><author><name></name></author><category term="Algorithms" /><category term="Complexity Theory" /><category term="NP-Hard" /><summary type="html"><![CDATA[A comprehensive guide to reducing from Clique to prove other problems are NP-complete, with common reduction questions and detailed answers.]]></summary></entry><entry><title type="html">Reductions from Integer Linear Programming: Common Questions and Answers</title><link href="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/reductions-from-ilp/" rel="alternate" type="text/html" title="Reductions from Integer Linear Programming: Common Questions and Answers" /><published>2025-11-21T00:00:00+00:00</published><updated>2025-11-21T00:00:00+00:00</updated><id>https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/reductions-from-ilp</id><content type="html" xml:base="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/reductions-from-ilp/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>Integer Linear Programming (ILP) is a fundamental optimization problem proven NP-complete by reduction from 3-SAT. This post provides answers to common reduction questions when using ILP to prove other problems are NP-complete.</p>

<h2 id="problem-definition-integer-linear-programming">Problem Definition: Integer Linear Programming</h2>

<p><strong>ILP Problem:</strong></p>
<ul>
  <li><strong>Input:</strong> Matrix A, vectors b, c, integer k</li>
  <li><strong>Output:</strong> YES if there exists integer vector x such that Ax ≤ b and c^T x ≥ k, NO otherwise</li>
</ul>

<p><strong>Key:</strong> Variables must be integers (unlike LP which is polynomial-time).</p>

<h2 id="common-reduction-questions">Common Reduction Questions</h2>

<h3 id="q1-how-do-you-reduce-ilp-to-0-1-ilp">Q1: How do you reduce ILP to 0-1 ILP?</h3>

<p><strong>Answer:</strong> Use binary expansion of integer variables.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Given ILP instance with variables xᵢ ∈ ℤ, bounds xᵢ ≤ M</li>
  <li>For each xᵢ, create ⌈log₂(M+1)⌉ binary variables</li>
  <li>Represent xᵢ = ∑ⱼ 2ʲ · yᵢⱼ where yᵢⱼ ∈ {0,1}</li>
  <li>Convert constraints using binary representation</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>ILP feasible ↔ 0-1 ILP feasible</li>
  <li>Binary expansion preserves integer values</li>
</ul>

<p><strong>Time:</strong> O(n log M)</p>

<h3 id="q2-how-do-you-reduce-ilp-to-knapsack">Q2: How do you reduce ILP to Knapsack?</h3>

<p><strong>Answer:</strong> Encode ILP constraints as knapsack constraints.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Given ILP instance: maximize c^T x subject to Ax ≤ b, x ≥ 0, x integer</li>
  <li>Create Knapsack instance:
    <ul>
      <li>Items: Each variable xᵢ becomes item</li>
      <li>Weights: Constraint coefficients</li>
      <li>Values: Objective coefficients</li>
      <li>Capacity: Constraint bounds</li>
    </ul>
  </li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>ILP feasible ↔ Knapsack has solution</li>
  <li>Constraints become capacity limits</li>
</ul>

<p><strong>Time:</strong> O(nm)</p>

<h3 id="q3-how-do-you-reduce-ilp-to-set-cover">Q3: How do you reduce ILP to Set Cover?</h3>

<p><strong>Answer:</strong> Encode ILP as covering problem.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Given ILP instance with 0-1 variables</li>
  <li>Universe: All constraints</li>
  <li>Sets: Variable assignments satisfying constraints</li>
  <li>Target: Cover all constraints</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>ILP feasible ↔ Set Cover exists</li>
  <li>Variables cover constraints</li>
</ul>

<p><strong>Time:</strong> O(2ⁿ · m) (exponential, but reduction is valid)</p>

<h3 id="q4-how-do-you-reduce-ilp-to-scheduling">Q4: How do you reduce ILP to Scheduling?</h3>

<p><strong>Answer:</strong> Encode ILP constraints as scheduling constraints.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Given ILP instance</li>
  <li>Jobs: Variables become jobs</li>
  <li>Resources: Constraints become resource limits</li>
  <li>Time: Objective becomes makespan</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>ILP feasible ↔ Scheduling feasible</li>
  <li>Constraints become resource/time limits</li>
</ul>

<p><strong>Time:</strong> O(nm)</p>

<h3 id="q5-how-do-you-reduce-ilp-to-network-flow">Q5: How do you reduce ILP to Network Flow?</h3>

<p><strong>Answer:</strong> Special ILP structures map to flow problems.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Given ILP with special structure (e.g., transportation problem)</li>
  <li>Create flow network:
    <ul>
      <li>Nodes: Variables/constraints</li>
      <li>Edges: Variable-constraint relationships</li>
      <li>Capacities: Constraint bounds</li>
    </ul>
  </li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>ILP feasible ↔ Flow exists</li>
  <li>Flow conservation ↔ Constraint satisfaction</li>
</ul>

<p><strong>Time:</strong> O(nm)</p>

<h2 id="reduction-patterns-from-ilp">Reduction Patterns from ILP</h2>

<h3 id="pattern-1-binary-expansion">Pattern 1: Binary Expansion</h3>
<ul>
  <li><strong>Use when:</strong> Target problem requires binary variables</li>
  <li><strong>Examples:</strong> 0-1 ILP</li>
  <li><strong>Key:</strong> Expand integers in binary</li>
</ul>

<h3 id="pattern-2-constraint-encoding">Pattern 2: Constraint Encoding</h3>
<ul>
  <li><strong>Use when:</strong> Target problem has similar constraints</li>
  <li><strong>Examples:</strong> Knapsack, Scheduling</li>
  <li><strong>Key:</strong> Map constraints directly</li>
</ul>

<h3 id="pattern-3-special-structures">Pattern 3: Special Structures</h3>
<ul>
  <li><strong>Use when:</strong> ILP has special form</li>
  <li><strong>Examples:</strong> Network Flow, Transportation</li>
  <li><strong>Key:</strong> Exploit problem structure</li>
</ul>

<h2 id="key-takeaways">Key Takeaways</h2>

<ol>
  <li><strong>Binary expansion:</strong> Convert to 0-1 ILP</li>
  <li><strong>Constraint mapping:</strong> Direct encoding to similar problems</li>
  <li><strong>Special structures:</strong> Exploit problem-specific structure</li>
  <li><strong>Generalization:</strong> ILP generalizes many problems</li>
</ol>

<h2 id="practice-problems">Practice Problems</h2>

<ol>
  <li>Reduce ILP to Multiple Knapsack</li>
  <li>Reduce ILP to Resource Allocation</li>
  <li>Reduce ILP to Assignment Problem</li>
</ol>

<hr />

<p>ILP reductions often use binary expansion and constraint encoding techniques.</p>]]></content><author><name></name></author><category term="Algorithms" /><category term="Complexity Theory" /><category term="NP-Hard" /><summary type="html"><![CDATA[A comprehensive guide to reducing from Integer Linear Programming to prove other problems are NP-complete, with common reduction questions and detailed answers.]]></summary></entry><entry><title type="html">Reductions from Independent Set: Common Questions and Answers</title><link href="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/reductions-from-independent-set/" rel="alternate" type="text/html" title="Reductions from Independent Set: Common Questions and Answers" /><published>2025-11-21T00:00:00+00:00</published><updated>2025-11-21T00:00:00+00:00</updated><id>https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/reductions-from-independent-set</id><content type="html" xml:base="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/11/21/reductions-from-independent-set/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>Independent Set is a fundamental graph problem proven NP-complete by reduction from 3-SAT. This post provides answers to common reduction questions when using Independent Set to prove other problems are NP-complete.</p>

<h2 id="problem-definition-independent-set">Problem Definition: Independent Set</h2>

<p><strong>Independent Set Problem:</strong></p>
<ul>
  <li><strong>Input:</strong> Graph G = (V, E) and integer k</li>
  <li><strong>Output:</strong> YES if G has an independent set of size ≥ k, NO otherwise</li>
</ul>

<p><strong>Independent Set:</strong> A subset of vertices where no two vertices are connected by an edge.</p>

<h2 id="common-reduction-questions">Common Reduction Questions</h2>

<h3 id="q1-how-do-you-reduce-independent-set-to-clique">Q1: How do you reduce Independent Set to Clique?</h3>

<p><strong>Answer:</strong> Use complement graph.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Given Independent Set instance: graph G, integer k</li>
  <li>Create complement graph G̅</li>
  <li>Return Clique: graph G̅, integer k</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>Independent set of size k in G ↔ Clique of size k in G̅</li>
  <li>No edges in G ↔ all edges in G̅</li>
</ul>

<p><strong>Time:</strong> O(n²)</p>

<h3 id="q2-how-do-you-reduce-independent-set-to-vertex-cover">Q2: How do you reduce Independent Set to Vertex Cover?</h3>

<p><strong>Answer:</strong> Use complement relationship.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Given Independent Set instance: graph G, integer k</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Return Vertex Cover: graph G, k’ =</td>
          <td>V</td>
          <td>- k</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Independent set of size k ↔ Vertex cover of size</td>
          <td>V</td>
          <td>- k</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>S is independent set ↔ V \ S is vertex cover</li>
</ul>

<p><strong>Time:</strong> O(1)</p>

<h3 id="q3-how-do-you-reduce-independent-set-to-maximum-cut">Q3: How do you reduce Independent Set to Maximum Cut?</h3>

<p><strong>Answer:</strong> Encode independent set as one side of cut.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Given Independent Set instance: graph G, integer k</li>
  <li>Create graph G’ by adding edges if needed</li>
  <li>Return Maximum Cut: graph G’, target cut size</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>Independent set of size k ↔ Cut with k vertices on one side, no edges within</li>
</ul>

<p><strong>Time:</strong> O(n + m)</p>

<h3 id="q4-how-do-you-reduce-independent-set-to-graph-coloring">Q4: How do you reduce Independent Set to Graph Coloring?</h3>

<p><strong>Answer:</strong> Use independent sets as color classes.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Given Independent Set instance: graph G, integer k</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Return Graph Coloring: graph G, number of colors =</td>
          <td>V</td>
          <td>- k + 1</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Independent set of size k ↔ Can color with</td>
          <td>V</td>
          <td>- k + 1 colors</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>Large independent set ↔ Few colors needed</li>
</ul>

<p><strong>Time:</strong> O(1)</p>

<h3 id="q5-how-do-you-reduce-independent-set-to-dominating-set">Q5: How do you reduce Independent Set to Dominating Set?</h3>

<p><strong>Answer:</strong> Independent set + neighbors form dominating set.</p>

<p><strong>Reduction:</strong></p>
<ul>
  <li>Given Independent Set instance: graph G, integer k</li>
  <li>Return Dominating Set: graph G, k’ = k + (some function of neighbors)</li>
</ul>

<p><strong>Correctness:</strong></p>
<ul>
  <li>Independent set of size k → Can extend to dominating set</li>
  <li>Requires careful construction</li>
</ul>

<p><strong>Time:</strong> O(n + m)</p>

<h2 id="reduction-patterns-from-independent-set">Reduction Patterns from Independent Set</h2>

<h3 id="pattern-1-complement-graph">Pattern 1: Complement Graph</h3>
<ul>
  <li><strong>Use when:</strong> Target problem is complement structure</li>
  <li><strong>Examples:</strong> Clique</li>
  <li><strong>Key:</strong> Complement preserves no-edge property</li>
</ul>

<h3 id="pattern-2-complement-set">Pattern 2: Complement Set</h3>
<ul>
  <li><strong>Use when:</strong> Target problem uses complement vertices</li>
  <li><strong>Examples:</strong> Vertex Cover</li>
  <li><strong>Key:</strong> V \ S relationship</li>
</ul>

<h3 id="pattern-3-partitioncut">Pattern 3: Partition/Cut</h3>
<ul>
  <li><strong>Use when:</strong> Target problem partitions vertices</li>
  <li><strong>Examples:</strong> Maximum Cut, Graph Partitioning</li>
  <li><strong>Key:</strong> Independent set forms one partition</li>
</ul>

<h2 id="key-takeaways">Key Takeaways</h2>

<ol>
  <li><strong>Complement graph:</strong> Clique reductions</li>
  <li><strong>Complement set:</strong> Vertex cover reductions</li>
  <li><strong>Partition problems:</strong> Cuts and colorings</li>
  <li><strong>Selection problems:</strong> Many reduce from IS</li>
</ol>

<h2 id="practice-problems">Practice Problems</h2>

<ol>
  <li>Reduce Independent Set to Set Packing</li>
  <li>Reduce Independent Set to Maximum Weight Independent Set</li>
  <li>Reduce Independent Set to Clique Cover</li>
</ol>

<hr />

<p>Independent Set reductions often use complement relationships and graph transformations.</p>]]></content><author><name></name></author><category term="Algorithms" /><category term="Complexity Theory" /><category term="NP-Hard" /><summary type="html"><![CDATA[A comprehensive guide to reducing from Independent Set to prove other problems are NP-complete, with common reduction questions and detailed answers.]]></summary></entry></feed>
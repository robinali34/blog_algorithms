<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Linear Programming: Reductions | Robina Li</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Linear Programming: Reductions" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An introduction to Linear Programming, its polynomial-time solvability, and how it relates to reductions in complexity theory, including LP relaxations, duality, and reductions to/from LP." />
<meta property="og:description" content="An introduction to Linear Programming, its polynomial-time solvability, and how it relates to reductions in complexity theory, including LP relaxations, duality, and reductions to/from LP." />
<link rel="canonical" href="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/01/15/linear-programming-reductions/" />
<meta property="og:url" content="https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/01/15/linear-programming-reductions/" />
<meta property="og:site_name" content="Robina Li" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-01-15T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Linear Programming: Reductions" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-01-15T00:00:00+00:00","datePublished":"2025-01-15T00:00:00+00:00","description":"An introduction to Linear Programming, its polynomial-time solvability, and how it relates to reductions in complexity theory, including LP relaxations, duality, and reductions to/from LP.","headline":"Linear Programming: Reductions","mainEntityOfPage":{"@type":"WebPage","@id":"https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/01/15/linear-programming-reductions/"},"url":"https://robinali34.github.io/blog_algorithms//blog_algorithms/2025/01/15/linear-programming-reductions/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog_algorithms/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://robinali34.github.io/blog_algorithms//blog_algorithms/feed.xml" title="Robina Li" /></head>

<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog_algorithms/">Robina Li</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          <a class="page-link" href="/blog_algorithms/posts/">All Posts</a><a class="page-link" href="/blog_algorithms/about/">About</a></div>
      </nav></div>
</header>

<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Linear Programming: Reductions</h1>
    <div class="post-meta-wrapper">
      <p class="post-meta">
        <time class="dt-published" datetime="2025-01-15T00:00:00+00:00" itemprop="datePublished">Jan 15, 2025
        </time></p><div class="post-categories"><span class="category-tag">Algorithms</span><span class="category-tag">Complexity Theory</span><span class="category-tag">Linear Programming</span><span class="category-tag">Optimization</span></div></div>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h2 id="introduction">Introduction</h2>

<p>Linear Programming (LP) occupies a unique position in complexity theory: it’s one of the few optimization problems that can be solved in polynomial time, yet it’s closely related to many NP-complete problems through the concept of LP relaxations. Understanding Linear Programming and its role in reductions is crucial for understanding approximation algorithms, integer programming, and the boundary between polynomial-time and NP-complete problems.</p>

<h2 id="what-is-linear-programming">What is Linear Programming?</h2>

<p>Linear Programming asks: <strong>Given linear constraints and a linear objective function, find values for variables that satisfy the constraints and optimize the objective.</strong></p>

<h3 id="problem-definition">Problem Definition</h3>

<p><strong>Linear Programming (LP) Problem:</strong></p>

<p><strong>Input:</strong></p>
<ul>
  <li>A matrix A in mathbb{R}^{m times n} (constraint coefficients)</li>
  <li>A vector b in mathbb{R}^m (constraint bounds)</li>
  <li>A vector c in mathbb{R}^n (objective coefficients)</li>
</ul>

<p><strong>Output:</strong></p>
<ul>
  <li>A vector x in mathbb{R}^n that:
    <ul>
      <li>Satisfies Ax leq b (or Ax = b, or Ax geq b, or mixed)</li>
      <li>Satisfies x geq 0 (non-negativity constraints, if present)</li>
      <li>Maximizes (or minimizes) c^T x</li>
    </ul>
  </li>
</ul>

<p><strong>Standard Form:</strong></p>
<ul>
  <li>Maximize c^T x</li>
  <li>Subject to Ax leq b and x geq 0</li>
</ul>

<p><strong>Canonical Form:</strong></p>
<ul>
  <li>Maximize c^T x</li>
  <li>Subject to Ax = b and x geq 0</li>
</ul>

<h3 id="example">Example</h3>

<p>Consider the LP:</p>

<p><strong>Maximize:</strong> 3x₁ + 2x₁</p>

<p><strong>Subject to:</strong></p>
<ul>
  <li>2x₁ + x₁ leq 6</li>
  <li>x₁ + 2x₁ leq 8</li>
  <li>x₁, x₁ geq 0</li>
</ul>

<p><strong>Graphical Solution:</strong></p>
<ul>
  <li>Feasible region is a polygon</li>
  <li>Optimal solution is at a vertex (corner point)</li>
  <li>Optimal: (x₁, x₁) = (4/3, 10/3) with objective value 32/3 \approx 10.67</li>
</ul>

<p><strong>Key Insight:</strong> The optimal solution of an LP always occurs at a vertex of the feasible region (if the problem is bounded).</p>

<h2 id="why-lp-is-in-p">Why LP is in P</h2>

<p>Unlike Integer Linear Programming, <strong>Linear Programming is solvable in polynomial time</strong>.</p>

<h3 id="algorithms-for-lp">Algorithms for LP</h3>

<p><strong>1. Simplex Method (Dantzig, 1947):</strong></p>
<ul>
  <li>Moves from vertex to vertex along edges</li>
  <li>Very efficient in practice</li>
  <li><strong>Worst-case:</strong> Exponential (Klee-Minty examples)</li>
  <li><strong>Average-case:</strong> Polynomial</li>
</ul>

<p><strong>2. Ellipsoid Method (Khachiyan, 1979):</strong></p>
<ul>
  <li>First polynomial-time algorithm for LP</li>
  <li>O(n^4 L) time where L is input size</li>
  <li>Not practical due to large constants</li>
</ul>

<p><strong>3. Interior-Point Methods (Karmarkar, 1984):</strong></p>
<ul>
  <li>Polynomial-time: O(n^{3.5} L) time</li>
  <li>Practical and widely used</li>
  <li>Modern implementations are very efficient</li>
</ul>

<p><strong>Result:</strong> LP ∈ P (solvable in polynomial time)</p>

<h2 id="lp-relaxation-a-key-reduction-technique">LP Relaxation: A Key Reduction Technique</h2>

<p>One of the most important uses of LP in complexity theory is the concept of <strong>LP relaxation</strong>.</p>

<h3 id="what-is-lp-relaxation">What is LP Relaxation?</h3>

<p>Given an Integer Linear Programming (ILP) problem:</p>
<ul>
  <li><strong>ILP:</strong> Variables must be integers</li>
  <li><strong>LP Relaxation:</strong> Allow variables to be real numbers</li>
</ul>

<p><strong>Key Insight:</strong> The optimal value of the LP relaxation provides a <strong>bound</strong> on the optimal value of the ILP:</p>
<ul>
  <li>For maximization: LP optimal ≥ ILP optimal</li>
  <li>For minimization: LP optimal ≤ ILP optimal</li>
</ul>

<h3 id="example-vertex-cover-lp-relaxation">Example: Vertex Cover LP Relaxation</h3>

<p><strong>ILP for Vertex Cover:</strong></p>
<ul>
  <li>Variables: x_v ∈ {0,1} for each vertex v</li>
  <li>Constraints: x_u + x_v ≥ 1 for each edge (u,v)</li>
  <li>Objective: Minimize sum_v x_v</li>
</ul>

<p><strong>LP Relaxation:</strong></p>
<ul>
  <li>Variables: x_v in [0,1] (continuous, not integer)</li>
  <li>Same constraints and objective</li>
</ul>

<p><strong>Result:</strong> LP optimal ≤ ILP optimal (since we relaxed constraints)</p>

<p><strong>2-Approximation Algorithm:</strong></p>
<ol>
  <li>Solve LP relaxation</li>
  <li>Round: Include vertex v if x_v geq 1/2</li>
  <li>This gives a 2-approximation for Vertex Cover!</li>
</ol>

<h2 id="reductions-involving-lp">Reductions Involving LP</h2>

<h3 id="reduction-ilp-to-lp-relaxation">Reduction: ILP to LP (Relaxation)</h3>

<p><strong>ILP ≤ₚ LP (via relaxation):</strong></p>
<ul>
  <li>Given ILP instance, remove integrality constraints</li>
  <li>Solve LP relaxation</li>
  <li>If LP solution is integer, we’re done</li>
  <li>Otherwise, use branch-and-bound or cutting planes</li>
</ul>

<p><strong>Note:</strong> This is not a polynomial-time reduction in the complexity sense, but it’s a practical technique.</p>

<h3 id="reduction-lp-to-feasibility">Reduction: LP to Feasibility</h3>

<p><strong>LP Optimization ≤ₚ LP Feasibility:</strong></p>
<ul>
  <li>Given LP: maximize c^T x subject to Ax leq b, x geq 0</li>
  <li>Add constraint: c^T x geq k (where k is a guess for optimal value)</li>
  <li>Use binary search on k to find optimal value</li>
  <li>This reduces optimization to feasibility checking</li>
</ul>

<h3 id="reduction-general-lp-to-standard-form">Reduction: General LP to Standard Form</h3>

<p><strong>General LP ≤ₚ Standard Form LP:</strong></p>
<ul>
  <li>Convert inequalities to equations using slack variables</li>
  <li>Convert unconstrained variables: x = x^+ - x^- where x^+, x^- geq 0</li>
  <li>Convert maximization to minimization: negate objective</li>
  <li>All conversions are polynomial-time</li>
</ul>

<h2 id="lp-duality-and-reductions">LP Duality and Reductions</h2>

<h3 id="duality-theorem">Duality Theorem</h3>

<p>Every LP has a <strong>dual</strong> LP:</p>

<p><strong>Primal:</strong> Maximize c^T x subject to Ax leq b, x geq 0</p>

<p><strong>Dual:</strong> Minimize b^T y subject to A^T y geq c, y geq 0</p>

<p><strong>Strong Duality:</strong> If both have feasible solutions, then:</p>
<ul>
  <li>Primal optimal = Dual optimal</li>
</ul>

<p><strong>Weak Duality:</strong> For any feasible x and y:</p>
<ul>
  <li>c^T x leq b^T y</li>
</ul>

<h3 id="using-duality-in-reductions">Using Duality in Reductions</h3>

<p>Duality provides a powerful tool for:</p>
<ol>
  <li><strong>Proving optimality:</strong> If primal and dual have same value, both are optimal</li>
  <li><strong>Finding bounds:</strong> Dual provides upper bounds (for maximization)</li>
  <li><strong>Sensitivity analysis:</strong> Understanding how changes affect solution</li>
  <li><strong>Designing algorithms:</strong> Many algorithms use duality</li>
</ol>

<h2 id="lp-in-approximation-algorithms">LP in Approximation Algorithms</h2>

<p>LP relaxation is fundamental to many approximation algorithms.</p>

<h3 id="vertex-cover-2-approximation">Vertex Cover: 2-Approximation</h3>

<p><strong>Algorithm:</strong></p>
<ol>
  <li>Solve LP relaxation: minimize sum_v x_v subject to x_u + x_v geq 1 for all edges</li>
  <li>Round: S = {v : x_v geq 1/2}</li>
  <li>Return S as vertex cover</li>
</ol>

<p><strong>Analysis:</strong></p>
<ul>
  <li>S is a vertex cover (each edge has at least one endpoint with x_v geq 1/2)</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>S</td>
          <td>= sum_{v in S} 1 leq sum_{v in S} 2x_v leq 2 cdot text{LP optimal} leq 2 cdot text{ILP optimal}</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>Therefore, 2-approximation</li>
</ul>

<h3 id="set-cover-lp-based-approximation">Set Cover: LP-Based Approximation</h3>

<p><strong>Set Cover ILP:</strong></p>
<ul>
  <li>Variables: x_S in {0,1} for each set S</li>
  <li>Constraints: sum_{S: e in S} x_S geq 1 for each element e</li>
  <li>Objective: Minimize sum_S x_S</li>
</ul>

<p><strong>LP Relaxation + Rounding:</strong></p>
<ul>
  <li>Solve LP relaxation</li>
  <li>Use randomized rounding or greedy rounding</li>
  <li>Achieves O(\log n) approximation (or better with specific techniques)</li>
</ul>

<h3 id="maximum-flow-lp-formulation">Maximum Flow: LP Formulation</h3>

<p><strong>Max Flow as LP:</strong></p>
<ul>
  <li>Variables: flow f_e on each edge e</li>
  <li>Constraints: flow conservation, capacity constraints</li>
  <li>Objective: maximize flow from source to sink</li>
</ul>

<p><strong>Result:</strong> Max flow can be solved via LP (though specialized algorithms are faster)</p>

<h2 id="reductions-from-np-complete-problems-to-lp">Reductions from NP-Complete Problems to LP</h2>

<p>While LP is polynomial-time, we can reduce NP-complete problems to LP feasibility questions.</p>

<h3 id="3-sat-to-lp-feasibility">3-SAT to LP Feasibility</h3>

<p><strong>Reduction:</strong></p>
<ul>
  <li>For 3-SAT instance, create LP:
    <ul>
      <li>Variables: x_i in [0,1] for each Boolean variable</li>
      <li>For clause (l_1  ∨  l_2  ∨  l_3): constraint ensuring at least one literal is “true”</li>
      <li>But LP doesn’t naturally encode Boolean logic…</li>
    </ul>
  </li>
</ul>

<p><strong>Better:</strong> Reduce to ILP, then use LP relaxation</p>
<ul>
  <li>3-SAT → ILP (as we saw earlier)</li>
  <li>ILP feasibility can be checked via LP (but LP solution might not be integer)</li>
</ul>

<p><strong>Key Point:</strong> LP relaxation gives bounds, but doesn’t solve the original problem.</p>

<h2 id="lp-rounding-techniques">LP Rounding Techniques</h2>

<p>Various rounding techniques convert LP solutions to integer solutions:</p>

<h3 id="deterministic-rounding">Deterministic Rounding</h3>

<p><strong>Example - Vertex Cover:</strong></p>
<ul>
  <li>Round x_v ≥ 1/2 to 1, else 0</li>
  <li>Guarantees feasibility and approximation ratio</li>
</ul>

<h3 id="randomized-rounding">Randomized Rounding</h3>

<p><strong>Example - Set Cover:</strong></p>
<ul>
  <li>Include set S with probability proportional to x_S^* (LP solution)</li>
  <li>Expected cost equals LP cost</li>
  <li>May need derandomization</li>
</ul>

<h3 id="dependent-rounding">Dependent Rounding</h3>

<p><strong>Example - Matching:</strong></p>
<ul>
  <li>Round edges while maintaining constraints</li>
  <li>More sophisticated than independent rounding</li>
</ul>

<h2 id="practical-implications">Practical Implications</h2>

<h3 id="why-lp-matters">Why LP Matters</h3>

<p>Linear Programming is crucial because:</p>

<ol>
  <li><strong>Polynomial-Time Solvability:</strong> Can solve large instances efficiently</li>
  <li><strong>LP Relaxation:</strong> Provides bounds for NP-complete problems</li>
  <li><strong>Approximation Algorithms:</strong> Foundation for many approximation schemes</li>
  <li><strong>Duality:</strong> Powerful theoretical and practical tool</li>
  <li><strong>Widespread Applications:</strong> Used in many real-world optimization problems</li>
</ol>

<h3 id="modern-lp-solvers">Modern LP Solvers</h3>

<p><strong>Commercial Solvers:</strong></p>
<ul>
  <li><strong>CPLEX:</strong> Industry standard, very fast</li>
  <li><strong>Gurobi:</strong> Excellent performance, good academic licenses</li>
  <li><strong>XPRESS:</strong> Commercial solver</li>
</ul>

<p><strong>Open-Source Solvers:</strong></p>
<ul>
  <li><strong>GLPK:</strong> GNU Linear Programming Kit</li>
  <li><strong>CLP:</strong> COIN-OR Linear Programming</li>
  <li><strong>HiGHS:</strong> Modern, high-performance solver</li>
</ul>

<p><strong>Interfaces:</strong></p>
<ul>
  <li><strong>PuLP</strong> (Python)</li>
  <li><strong>CVXPY</strong> (Python)</li>
  <li><strong>JuMP</strong> (Julia)</li>
  <li><strong>OR-Tools</strong> (Google)</li>
</ul>

<h3 id="real-world-applications">Real-World Applications</h3>

<p>LP has countless applications:</p>

<ol>
  <li><strong>Resource Allocation:</strong> Allocating limited resources optimally</li>
  <li><strong>Production Planning:</strong> Optimizing production schedules</li>
  <li><strong>Transportation:</strong> Network flow, transportation problems</li>
  <li><strong>Finance:</strong> Portfolio optimization, risk management</li>
  <li><strong>Scheduling:</strong> Workforce scheduling, project scheduling</li>
  <li><strong>Network Design:</strong> Designing efficient networks</li>
  <li><strong>Game Theory:</strong> Finding Nash equilibria in some games</li>
</ol>

<h2 id="runtime-analysis">Runtime Analysis</h2>

<h3 id="simplex-method">Simplex Method</h3>

<p><strong>Algorithm:</strong> Move from vertex to vertex along edges</p>
<ul>
  <li><strong>Time Complexity:</strong> Exponential worst-case (Klee-Minty examples), but polynomial average-case</li>
  <li><strong>Space Complexity:</strong> O(mn) for storing tableau</li>
  <li><strong>Practical Performance:</strong> Very efficient in practice, often faster than polynomial methods</li>
  <li><strong>Iterations:</strong> Typically O(m) to O(m+n) iterations</li>
</ul>

<h3 id="ellipsoid-method">Ellipsoid Method</h3>

<p><strong>Algorithm:</strong> Shrink ellipsoid containing feasible region</p>
<ul>
  <li><strong>Time Complexity:</strong> O(n^4L) where L is input size (bit complexity)</li>
  <li><strong>Space Complexity:</strong> O(n^2)</li>
  <li><strong>Significance:</strong> First proven polynomial-time algorithm for LP</li>
  <li><strong>Practical Performance:</strong> Not used in practice due to large constants</li>
</ul>

<h3 id="interior-point-methods">Interior-Point Methods</h3>

<p><strong>Algorithm:</strong> Move through interior of feasible region</p>
<ul>
  <li><strong>Time Complexity:</strong> O(n^{3.5}L) using path-following methods</li>
  <li><strong>Space Complexity:</strong> O(n^2) for storing matrices</li>
  <li><strong>Practical Performance:</strong> Very efficient, widely used in modern solvers</li>
  <li><strong>Iterations:</strong> Typically O(sqrt{n} log(1/epsilon)) iterations for \epsilon-accuracy</li>
</ul>

<h3 id="primal-dual-methods">Primal-Dual Methods</h3>

<p><strong>Algorithm:</strong> Solve primal and dual simultaneously</p>
<ul>
  <li><strong>Time Complexity:</strong> O(n^{3.5}L) similar to interior-point</li>
  <li><strong>Space Complexity:</strong> O(n^2)</li>
  <li><strong>Advantage:</strong> Can exploit structure better in some cases</li>
</ul>

<h3 id="special-cases">Special Cases</h3>

<p><strong>Network Flow Problems:</strong></p>
<ul>
  <li><strong>Time Complexity:</strong> O(n^2m) using specialized algorithms (faster than general LP)</li>
  <li><strong>Space Complexity:</strong> O(n + m)</li>
</ul>

<p><strong>Transportation Problems:</strong></p>
<ul>
  <li>Specialized algorithms can be more efficient than general LP</li>
</ul>

<h3 id="lp-relaxation-runtime">LP Relaxation Runtime</h3>

<p><strong>For ILP Relaxation:</strong></p>
<ul>
  <li><strong>Time Complexity:</strong> O(n^{3.5}L) - solve as regular LP</li>
  <li><strong>Space Complexity:</strong> O(mn)</li>
  <li><strong>Use:</strong> Provides bounds for branch-and-bound algorithms</li>
</ul>

<h3 id="modern-solvers">Modern Solvers</h3>

<p><strong>Commercial Solvers (CPLEX, Gurobi):</strong></p>
<ul>
  <li><strong>Time Complexity:</strong> Polynomial (interior-point or simplex)</li>
  <li><strong>Space Complexity:</strong> O(mn)</li>
  <li><strong>Practical Performance:</strong> Can solve instances with millions of variables and constraints</li>
  <li><strong>Techniques:</strong> Preprocessing, advanced pivoting, parallel processing</li>
</ul>

<h3 id="verification-complexity">Verification Complexity</h3>

<p><strong>Given a candidate solution:</strong></p>
<ul>
  <li><strong>Time Complexity:</strong> O(mn) - verify all constraints satisfied</li>
  <li><strong>Space Complexity:</strong> O(1) additional space</li>
  <li>This polynomial-time verifiability is straightforward for LP</li>
</ul>

<h2 id="key-takeaways">Key Takeaways</h2>

<ol>
  <li><strong>LP is in P:</strong> Solvable in polynomial time using interior-point methods</li>
  <li><strong>LP Relaxation:</strong> Fundamental technique for approximating NP-complete problems</li>
  <li><strong>Duality:</strong> Powerful theoretical tool with practical applications</li>
  <li><strong>Approximation Algorithms:</strong> Many use LP relaxation + rounding</li>
  <li><strong>Reductions:</strong> LP provides bounds and approximations, not exact solutions for integer problems</li>
</ol>

<h2 id="reduction-summary">Reduction Summary</h2>

<p><strong>Key Reductions Involving LP:</strong></p>

<ol>
  <li><strong>ILP → LP (Relaxation):</strong>
    <ul>
      <li>Remove integrality constraints</li>
      <li>Provides upper/lower bounds</li>
      <li>Used in branch-and-bound</li>
    </ul>
  </li>
  <li><strong>LP Optimization → LP Feasibility:</strong>
    <ul>
      <li>Use binary search on objective value</li>
      <li>Reduces optimization to feasibility</li>
    </ul>
  </li>
  <li><strong>General LP → Standard Form:</strong>
    <ul>
      <li>Convert to standard form using slack variables</li>
      <li>All conversions are polynomial-time</li>
    </ul>
  </li>
  <li><strong>NP-Complete → LP Relaxation:</strong>
    <ul>
      <li>Many NP-complete problems have natural LP relaxations</li>
      <li>LP solution provides approximation bounds</li>
    </ul>
  </li>
</ol>

<h2 id="further-reading">Further Reading</h2>

<ul>
  <li><strong>Linear Programming:</strong> Chvátal’s “Linear Programming” or Vanderbei’s “Linear Programming”</li>
  <li><strong>Interior-Point Methods:</strong> Nesterov &amp; Nemirovskii’s work on interior-point methods</li>
  <li><strong>Approximation Algorithms:</strong> Vazirani’s “Approximation Algorithms” covers LP-based approximations</li>
  <li><strong>Duality:</strong> Understanding the dual simplex method and sensitivity analysis</li>
  <li><strong>Modern Solvers:</strong> Documentation for CPLEX, Gurobi, or other solvers</li>
</ul>

<h2 id="practice-problems">Practice Problems</h2>

<ol>
  <li><strong>Formulate as LP</strong>: Convert the following to LP:
    <ul>
      <li>You have resources and want to maximize profit</li>
      <li>Each product uses certain amounts of resources</li>
      <li>You have limited resources</li>
      <li>Products have different profits</li>
    </ul>
  </li>
  <li>
    <p><strong>LP Relaxation</strong>: For a Vertex Cover instance, write the LP relaxation. What is the relationship between LP optimal and ILP optimal?</p>
  </li>
  <li><strong>Duality</strong>: Write the dual of the following LP:
    <ul>
      <li>Maximize 3x₁ + 2x₁</li>
      <li>Subject to 2x₁ + x₁ ≤ 6, x₁ + 2x₁ ≤ 8, x₁, x₁ ≥ 0</li>
    </ul>
  </li>
  <li>
    <p><strong>Rounding</strong>: Prove that the LP-based 2-approximation for Vertex Cover is correct. What happens if we round at threshold 1/3 instead of 1/2?</p>
  </li>
  <li>
    <p><strong>Reduction</strong>: Show how to reduce LP optimization to LP feasibility using binary search. What is the time complexity?</p>
  </li>
  <li><strong>Standard Form</strong>: Convert the following to standard form:
    <ul>
      <li>Minimize x₁ - 2x₁</li>
      <li>Subject to x₁ + x₁ = 5, x₁ ≥ 0, x₁ unrestricted</li>
    </ul>
  </li>
  <li>
    <p><strong>Applications</strong>: Research one real-world application of LP. How is it formulated? What solver is used?</p>
  </li>
  <li>
    <p><strong>Approximation</strong>: Research the LP-based approximation for Set Cover. What approximation ratio does it achieve? How does rounding work?</p>
  </li>
  <li>
    <p><strong>Duality Applications</strong>: How is LP duality used in the design of algorithms? Research one example.</p>
  </li>
  <li><strong>Interior-Point Methods</strong>: Research how interior-point methods work. How do they differ from the simplex method?</li>
</ol>

<hr />

<p>Understanding Linear Programming and its role in reductions provides crucial insight into the boundary between polynomial-time and NP-complete problems. LP relaxation is one of the most powerful techniques for designing approximation algorithms and understanding the structure of optimization problems.</p>


  </div>

  <footer class="post-footer">
    <div class="post-navigation">
      <a href="/blog_algorithms/posts/" class="back-to-posts">← Back to All Posts</a>
    </div>
  </footer><a class="u-url" href="/blog_algorithms/2025/01/15/linear-programming-reductions/" hidden></a>
</article>


      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog_algorithms/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Robina Li</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Robina Li</li><li><a class="u-email" href="mailto:robinali34@gmail.com">robinali34@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><div class="social-links">
  <ul class="social-media-list"><li><a href="https://github.com/robinali34"><svg class="svg-icon"><use xlink:href="/blog_algorithms/assets/minima-social-icons.svg#github"></use></svg> <span class="username">robinali34</span></a></li></ul>
</div>

</div>

      <div class="footer-col footer-col-3">
        <p>Algorithms Blog - Graduate Algorithms course notes and resources</p>
      </div>
    </div>

  </div>

</footer>

</body>

</html>

